{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o5kKlVH0LRe-",
    "outputId": "9b71d366-80e9-45ef-b5b7-f200101bbac9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hazm in /usr/local/lib/python3.10/dist-packages (0.10.0)\n",
      "Requirement already satisfied: fasttext-wheel<0.10.0,>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from hazm) (0.9.2)\n",
      "Requirement already satisfied: flashtext<3.0,>=2.7 in /usr/local/lib/python3.10/dist-packages (from hazm) (2.7)\n",
      "Requirement already satisfied: gensim<5.0.0,>=4.3.1 in /usr/local/lib/python3.10/dist-packages (from hazm) (4.3.3)\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /usr/local/lib/python3.10/dist-packages (from hazm) (3.8.1)\n",
      "Requirement already satisfied: numpy==1.24.3 in /usr/local/lib/python3.10/dist-packages (from hazm) (1.24.3)\n",
      "Requirement already satisfied: python-crfsuite<0.10.0,>=0.9.9 in /usr/local/lib/python3.10/dist-packages (from hazm) (0.9.10)\n",
      "Requirement already satisfied: scikit-learn<2.0.0,>=1.2.2 in /usr/local/lib/python3.10/dist-packages (from hazm) (1.3.2)\n",
      "Requirement already satisfied: pybind11>=2.2 in /usr/local/lib/python3.10/dist-packages (from fasttext-wheel<0.10.0,>=0.9.2->hazm) (2.13.4)\n",
      "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from fasttext-wheel<0.10.0,>=0.9.2->hazm) (71.0.4)\n",
      "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim<5.0.0,>=4.3.1->hazm) (1.13.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim<5.0.0,>=4.3.1->hazm) (7.0.4)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->hazm) (8.1.7)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->hazm) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->hazm) (2024.5.15)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->hazm) (4.66.5)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<2.0.0,>=1.2.2->hazm) (3.5.0)\n",
      "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open>=1.8.1->gensim<5.0.0,>=4.3.1->hazm) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install hazm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "B94kr-7NCeg_"
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from hazm import word_tokenize\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-RWQ_yBqKrED",
    "outputId": "63bcaa85-01b5-4129-da34-ba314cd55736"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "B5MTNdxnKrAk"
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"/content/drive/MyDrive/Spell_correction/data.csv\")\n",
    "df=df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "L1QdGI5EKjO9"
   },
   "outputs": [],
   "source": [
    "df=df[df[\"main_category\"]==\"Main signs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "qWrWf-i0Kq-P"
   },
   "outputs": [],
   "source": [
    "df=df[[\"wrong_sentence\",\"correct_sentence\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "12PEhzyzNPMz"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "SG4Ep-C6Kq5Y"
   },
   "outputs": [],
   "source": [
    "#create vocabulay\n",
    "symbols_to_remove = ['@', '#', '$', '%', '^', '&', '*', '(', ')','[',']','{','}','\"','*\\r','+',',','ø','>>','CV','EXPO','None','alfare','fat','«','0-9','\\\\u200','\\\\u200c','\\\\u200f','\\\\u200e']\n",
    "# Create a regex pattern that matches any of the symbols in the list\n",
    "pattern = re.compile(f\"[{re.escape(''.join(symbols_to_remove))}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "l5sIXcS4MiJN"
   },
   "outputs": [],
   "source": [
    "# create a dictionary to convert the vocabulary to integers\n",
    "vocab_to_int = {}\n",
    "count = 0\n",
    "#tokenize and put <start> , < end >\n",
    "# Add special tokens to vocab_to_int\n",
    "codes = ['<PAD>','<eos>','<sos>','<UNK>']\n",
    "for code in codes:\n",
    "    vocab_to_int[code] = count\n",
    "    count += 1\n",
    "\n",
    "for index in df.index:\n",
    "    for word in word_tokenize(df.at[index,\"wrong_sentence\"]):\n",
    "        cleaned_string = pattern.sub(\"\", word)\n",
    "        # cleaned_string = new_word.replace(\"\\u200c\", \"\").replace(\"\\u200f\", \"\")\n",
    "        if cleaned_string not in vocab_to_int:\n",
    "            vocab_to_int[cleaned_string] = count\n",
    "            count += 1\n",
    "    for word in word_tokenize(df.at[index,\"correct_sentence\"]):\n",
    "        cleaned_string = pattern.sub(\"\", word)\n",
    "        # cleaned_string = new_word.replace(\"\\u200c\", \"\").replace(\"\\u200f\", \"\")\n",
    "        if cleaned_string not in vocab_to_int:\n",
    "            vocab_to_int[cleaned_string] = count\n",
    "            count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "a64Tv7QSKq8u"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FGZsZqTPNdc2",
    "outputId": "ea53ac1a-075c-44c0-83c3-62e5788ffa1b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The vocabulary contains 8136 words.\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(vocab_to_int)\n",
    "print(\"The vocabulary contains {} words.\".format(vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "T6_eq3Z6Ngl9"
   },
   "outputs": [],
   "source": [
    "# Create another dictionary to convert integers to their respective characters\n",
    "int_to_vocab = {}\n",
    "for word, value in vocab_to_int.items():\n",
    "    int_to_vocab[value] = word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "pxesL1_Cu7QL"
   },
   "outputs": [],
   "source": [
    "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(\n",
    "    df['correct_sentence'], target_vocab_size=len(vocab_to_int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1PTfM1LsvP8W",
    "outputId": "654f5b76-903a-46cf-c4ef-61bd0560a415"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded: [190, 407, 592, 18, 8044]\n",
      "Decoded: زبان فارسی زیبا است.\n"
     ]
    }
   ],
   "source": [
    "# Example text\n",
    "text = \"زبان فارسی زیبا است.\"\n",
    "\n",
    "# Encode the text\n",
    "encoded = tokenizer.encode(text)\n",
    "print(\"Encoded:\", encoded)\n",
    "\n",
    "# Decode the subwords back to the original text\n",
    "decoded = tokenizer.decode(encoded)\n",
    "print(\"Decoded:\", decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "uAAMKovYKq3D"
   },
   "outputs": [],
   "source": [
    "#change input to tokens_id\n",
    "def tokenizer(sentence):\n",
    "    tmp=[]\n",
    "    tmp.append(vocab_to_int[\"<sos>\"])\n",
    "    for word in word_tokenize(sentence):\n",
    "        cleaned_string = pattern.sub(\"\", word)\n",
    "        if cleaned_string not in vocab_to_int:\n",
    "            tmp.append(vocab_to_int[\"<UNK>\"])\n",
    "        else:\n",
    "          tmp.append(vocab_to_int[cleaned_string])\n",
    "    tmp.append(vocab_to_int[\"<eos>\"])\n",
    "    # padded_sequences = tf.keras.preprocessing.sequence.pad_sequences([tmp],maxlen=512 ,padding='post', value=vocab_to_int[\"<PAD>\"])\n",
    "    return tmp\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "_68o2y7HO9pK"
   },
   "outputs": [],
   "source": [
    "def detokenizer(tokens):\n",
    "    tmp=\"\"\n",
    "    for token in tokens:\n",
    "        tmp+=int_to_vocab[token]+\" \"\n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "LqEDJ6MgOVhP"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "jlZAWYfJKq0g"
   },
   "outputs": [],
   "source": [
    "lengths = []\n",
    "\n",
    "for ind in df.index:\n",
    "  wr_tokens = tokenizer(df.at[ind,\"wrong_sentence\"])\n",
    "  lengths.append(len(wr_tokens))\n",
    "  cor_tokens = tokenizer(df.at[ind,\"correct_sentence\"])\n",
    "  lengths.append(len(cor_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 452
    },
    "id": "PqKl2MKGKqxp",
    "outputId": "c3535d23-fd14-403e-dc9c-4cf618e53284"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.hist(lengths, np.linspace(0, 500, 101))\n",
    "plt.ylim(plt.ylim())\n",
    "max_length = max(lengths)\n",
    "plt.plot([max_length, max_length], plt.ylim())\n",
    "plt.title(f'Maximum tokens per example: {max_length}');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "kfCX3Lp9y5uv"
   },
   "outputs": [],
   "source": [
    "wrong_sentence=[]\n",
    "correct_sentence_inputs=[]\n",
    "correct_sentence_labels=[]\n",
    "# MAX_TOKENS=256\n",
    "for ind in df.index:\n",
    "  wrong=tokenizer(df.at[ind,\"wrong_sentence\"])\n",
    "  # wrong=wrong[:, :MAX_TOKENS]    # Trim to MAX_TOKENS.\n",
    "  wrong_sentence.append(tf.keras.preprocessing.sequence.pad_sequences([wrong],maxlen=256 ,padding='post', value=vocab_to_int[\"<PAD>\"],truncating='post')\n",
    ")\n",
    "  correct_inputs=tokenizer(df.at[ind,\"correct_sentence\"])\n",
    "  # correct_sentence = correct_inputs[:, :(MAX_TOKENS+1)]\n",
    "  correct_sentence_inputs_one = correct_inputs[:-1]     #drop <eos>\n",
    "  correct_sentence_labels_one=correct_inputs[1:]        #drop <sos>\n",
    "  correct_sentence_inputs .append(tf.keras.preprocessing.sequence.pad_sequences([correct_sentence_inputs_one],maxlen=256 ,padding='post', value=vocab_to_int[\"<PAD>\"],truncating='post') )\n",
    "  correct_sentence_labels .append(tf.keras.preprocessing.sequence.pad_sequences([correct_sentence_labels_one],maxlen=256 ,padding='post', value=vocab_to_int[\"<PAD>\"],truncating='post') )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "Or51PPsadcHR"
   },
   "outputs": [],
   "source": [
    "x=tokenizer(df.at[1,\"correct_sentence\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oNGaQgYv0Seb",
    "outputId": "46043633-1a60-45ce-c5cd-f120427b4559"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188\n",
      "187\n",
      "[2, 4, 5, 6, 7, 7, 8, 9, 10, 11, 12, 13, 14, 15, 7, 16, 17, 7, 18, 8, 10, 11, 19, 20, 21, 22, 23, 19, 24, 25, 26, 27, 26, 28, 29, 7, 30, 19, 31, 32, 11, 33, 34, 19, 35, 33, 23, 36, 37, 38, 39, 25, 26, 27, 26, 40, 41, 42, 43, 44, 24, 39, 45, 46, 47, 48, 33, 49, 9, 50, 51, 22, 16, 19, 48, 33, 49, 17, 52, 22, 16, 14, 12, 13, 53, 54, 55, 56, 16, 90, 57, 54, 55, 58, 56, 16, 59, 60, 29, 61, 12, 13, 62, 63, 64, 59, 60, 8, 33, 65, 66, 55, 63, 16, 67, 68, 61, 67, 69, 61, 67, 70, 61, 67, 71, 61, 53, 59, 60, 29, 61, 7, 72, 73, 8, 33, 65, 74, 75, 76, 77, 7, 78, 79, 19, 7, 10, 80, 59, 60, 33, 65, 81, 56, 82, 24, 7, 78, 79, 83, 54, 84, 33, 35, 22, 85, 19, 7, 78, 16, 73, 29, 61, 7, 78, 79, 73, 29, 54, 84, 86, 54, 87, 22, 85, 88, 89]\n"
     ]
    }
   ],
   "source": [
    "print(len(x))\n",
    "x=x[:-1]\n",
    "print(len(x))\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "9DZQPQgH0CUd"
   },
   "outputs": [],
   "source": [
    "df=pd.DataFrame({\n",
    "    \"wrong_sentence\":wrong_sentence,\n",
    "    \"correct_sentence_inputs\":correct_sentence_inputs,\n",
    "    \"correct_sentence_labels\":correct_sentence_labels\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 293
    },
    "id": "PeWFcg6M0d6d",
    "outputId": "034de728-9a07-4d28-b70a-f2dd59f08cf7"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"df\",\n  \"rows\": 4436,\n  \"fields\": [\n    {\n      \"column\": \"wrong_sentence\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"correct_sentence_inputs\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"correct_sentence_labels\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "df"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-331ec62c-3f83-4981-8b00-73e0a23eedd8\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wrong_sentence</th>\n",
       "      <th>correct_sentence_inputs</th>\n",
       "      <th>correct_sentence_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[2, 4, 5, 6, 7, 7, 8, 9, 10, 11, 12, 13, 14, ...</td>\n",
       "      <td>[[2, 4, 5, 6, 7, 7, 8, 9, 10, 11, 12, 13, 14, ...</td>\n",
       "      <td>[[4, 5, 6, 7, 7, 8, 9, 10, 11, 12, 13, 14, 15,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[2, 4, 5, 6, 7, 7, 8, 9, 10, 11, 12, 13, 14, ...</td>\n",
       "      <td>[[2, 4, 5, 6, 7, 7, 8, 9, 10, 11, 12, 13, 14, ...</td>\n",
       "      <td>[[4, 5, 6, 7, 7, 8, 9, 10, 11, 12, 13, 14, 15,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[2, 4, 5, 6, 7, 7, 8, 9, 10, 11, 12, 13, 14, ...</td>\n",
       "      <td>[[2, 4, 5, 6, 7, 7, 8, 9, 10, 11, 12, 13, 14, ...</td>\n",
       "      <td>[[4, 5, 6, 7, 7, 8, 9, 10, 11, 12, 13, 14, 15,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[2, 4, 5, 6, 7, 7, 8, 9, 10, 11, 12, 13, 14, ...</td>\n",
       "      <td>[[2, 4, 5, 6, 7, 7, 8, 9, 10, 11, 12, 13, 14, ...</td>\n",
       "      <td>[[4, 5, 6, 7, 7, 8, 9, 10, 11, 12, 13, 14, 15,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[2, 4, 5, 6, 7, 7, 8, 9, 10, 11, 12, 13, 14, ...</td>\n",
       "      <td>[[2, 4, 5, 6, 7, 7, 8, 9, 10, 11, 12, 13, 14, ...</td>\n",
       "      <td>[[4, 5, 6, 7, 7, 8, 9, 10, 11, 12, 13, 14, 15,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-331ec62c-3f83-4981-8b00-73e0a23eedd8')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-331ec62c-3f83-4981-8b00-73e0a23eedd8 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-331ec62c-3f83-4981-8b00-73e0a23eedd8');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-6a2231e8-f98a-4fa4-876c-09d2c95640fb\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6a2231e8-f98a-4fa4-876c-09d2c95640fb')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-6a2231e8-f98a-4fa4-876c-09d2c95640fb button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "                                      wrong_sentence  \\\n",
       "0  [[2, 4, 5, 6, 7, 7, 8, 9, 10, 11, 12, 13, 14, ...   \n",
       "1  [[2, 4, 5, 6, 7, 7, 8, 9, 10, 11, 12, 13, 14, ...   \n",
       "2  [[2, 4, 5, 6, 7, 7, 8, 9, 10, 11, 12, 13, 14, ...   \n",
       "3  [[2, 4, 5, 6, 7, 7, 8, 9, 10, 11, 12, 13, 14, ...   \n",
       "4  [[2, 4, 5, 6, 7, 7, 8, 9, 10, 11, 12, 13, 14, ...   \n",
       "\n",
       "                             correct_sentence_inputs  \\\n",
       "0  [[2, 4, 5, 6, 7, 7, 8, 9, 10, 11, 12, 13, 14, ...   \n",
       "1  [[2, 4, 5, 6, 7, 7, 8, 9, 10, 11, 12, 13, 14, ...   \n",
       "2  [[2, 4, 5, 6, 7, 7, 8, 9, 10, 11, 12, 13, 14, ...   \n",
       "3  [[2, 4, 5, 6, 7, 7, 8, 9, 10, 11, 12, 13, 14, ...   \n",
       "4  [[2, 4, 5, 6, 7, 7, 8, 9, 10, 11, 12, 13, 14, ...   \n",
       "\n",
       "                             correct_sentence_labels  \n",
       "0  [[4, 5, 6, 7, 7, 8, 9, 10, 11, 12, 13, 14, 15,...  \n",
       "1  [[4, 5, 6, 7, 7, 8, 9, 10, 11, 12, 13, 14, 15,...  \n",
       "2  [[4, 5, 6, 7, 7, 8, 9, 10, 11, 12, 13, 14, 15,...  \n",
       "3  [[4, 5, 6, 7, 7, 8, 9, 10, 11, 12, 13, 14, 15,...  \n",
       "4  [[4, 5, 6, 7, 7, 8, 9, 10, 11, 12, 13, 14, 15,...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "cLFO9YIIUYv6"
   },
   "outputs": [],
   "source": [
    "train,test=train_test_split(df,test_size=0.2,random_state=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "GPQwbsXcdAUX"
   },
   "outputs": [],
   "source": [
    "correct_label=tf.convert_to_tensor(train['correct_sentence_labels'].tolist(), dtype=tf.int64)\n",
    "wrong=tf.convert_to_tensor(train['wrong_sentence'].tolist(), dtype=tf.int64)\n",
    "correct_inputs=tf.convert_to_tensor(train['correct_sentence_inputs'].tolist(), dtype=tf.int64)\n",
    "\n",
    "\n",
    "\n",
    "correct_label_test=tf.convert_to_tensor(test['correct_sentence_labels'].tolist(), dtype=tf.int64)\n",
    "wrong_test=tf.convert_to_tensor(test['wrong_sentence'].tolist(), dtype=tf.int64)\n",
    "correct_inputs_test=tf.convert_to_tensor(test['correct_sentence_inputs'].tolist(), dtype=tf.int64)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "2q-yTYk5Fr1j"
   },
   "outputs": [],
   "source": [
    "correct_label=tf.squeeze(correct_label, axis=1)\n",
    "wrong=tf.squeeze(wrong, axis=1)\n",
    "correct_inputs=tf.squeeze(correct_inputs, axis=1)\n",
    "\n",
    "correct_label_test=tf.squeeze(correct_label_test, axis=1)\n",
    "wrong_test=tf.squeeze(wrong_test, axis=1)\n",
    "correct_inputs_test=tf.squeeze(correct_inputs_test, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "kiW7txpj4Zm8"
   },
   "outputs": [],
   "source": [
    "\n",
    "tensor_dict = (\n",
    "     wrong,\n",
    "     correct_inputs)\n",
    "tensor_dict_test = (\n",
    "     wrong_test,\n",
    "     correct_inputs_test\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "K2LpTcyT5Yp4"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "ZKdJwU6BRKfU"
   },
   "outputs": [],
   "source": [
    "dataset_train = tf.data.Dataset.from_tensor_slices((tensor_dict,correct_label))\n",
    "dataset_test = tf.data.Dataset.from_tensor_slices((tensor_dict_test,correct_label_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "KvRg1Jp0RYRh"
   },
   "outputs": [],
   "source": [
    "# dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aat0GsFGSm6K",
    "outputId": "620a4b0d-7dc9-41a7-833e-5018fb13e148"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[   2   24  238   22 7902  161  222  861  231 7903   33  861  306  366\n",
      " 7782   22 6638   29 7904  227  354  263  231 7905  199   22 7384  142\n",
      "  263  308  969   89    1    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0], shape=(256,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[   2   24  238   22 7902  161  222  517  231 7903   33  861  306  366\n",
      " 7782   22 6638   29 7904  227  354  263  231 7905  199   22 7384  142\n",
      "  263  308  969   89    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0], shape=(256,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[  24  238   22 7902  161  222  517  231 7903   33  861  306  366 7782\n",
      "   22 6638   29 7904  227  354  263  231 7905  199   22 7384  142  263\n",
      "  308  969   89    1    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0], shape=(256,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "for (wrong,correct_inputs) ,label in dataset_train.take(1):\n",
    "    print(wrong)\n",
    "    print(correct_inputs)\n",
    "    print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "pf7mMh-kRnvt"
   },
   "outputs": [],
   "source": [
    "\n",
    "MAX_TOKENS=256\n",
    "def prepare_batch(wrong_sentence,correct_sentence):\n",
    "    wrong_sentence = tokenizer(wrong_sentence)      # Output is ragged.\n",
    "    wrong_sentence = wrong_sentence[:, :MAX_TOKENS]    # Trim to MAX_TOKENS.\n",
    "    print(wrong_sentence)\n",
    "    wrong_sentence = wrong_sentence.to_tensor()  # Convert to 0-padded dense Tensor\n",
    "\n",
    "    correct_sentence = tokenizer(correct_sentence)\n",
    "    correct_sentence = correct_sentence[:, :(MAX_TOKENS+1)]\n",
    "    correct_sentence_inputs = correct_sentence[:, :-1].to_tensor()  # Drop the [END] tokens\n",
    "    correct_sentence_labels = correct_sentence[:, 1:].to_tensor()   # Drop the [START] tokens\n",
    "\n",
    "    return (wrong_sentence, correct_sentence_inputs), correct_sentence_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "Z1FQQqHuKqsS"
   },
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 20000\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "F3BAyAe0Q3zq"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "epWINy_lKqpV"
   },
   "outputs": [],
   "source": [
    "def make_batches(ds):\n",
    "  return (\n",
    "      ds\n",
    "      .shuffle(BUFFER_SIZE)\n",
    "      .batch(BATCH_SIZE))\n",
    "      # .map(prepare_batch, tf.data.AUTOTUNE)\n",
    "      # .prefetch(buffer_size=tf.data.AUTOTUNE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "Z-6k9N5fQ0qS"
   },
   "outputs": [],
   "source": [
    "# Create training and validation set batches.\n",
    "train_batches = make_batches(dataset_train)\n",
    "val_batches = make_batches(dataset_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "PB3CRNX-8Wzg"
   },
   "outputs": [],
   "source": [
    "# for x,c in train_batches.take(1):\n",
    "#   print(x)\n",
    "#   print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "Jgt0XnfxCm-L"
   },
   "outputs": [],
   "source": [
    "def positional_encoding(length, depth):\n",
    "  depth = depth/2\n",
    "\n",
    "  positions = np.arange(length)[:, np.newaxis]     # (seq, 1)\n",
    "  depths = np.arange(depth)[np.newaxis, :]/depth   # (1, depth)\n",
    "\n",
    "  angle_rates = 1 / (10000**depths)         # (1, depth)\n",
    "  angle_rads = positions * angle_rates      # (pos, depth)\n",
    "\n",
    "  pos_encoding = np.concatenate(\n",
    "      [np.sin(angle_rads), np.cos(angle_rads)],\n",
    "      axis=-1)\n",
    "\n",
    "  return tf.cast(pos_encoding, dtype=tf.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "IO5qLxJlCvpT"
   },
   "outputs": [],
   "source": [
    "class PositionalEmbedding(tf.keras.layers.Layer):\n",
    "  def __init__(self, vocab_size, d_model):\n",
    "    super().__init__()\n",
    "    self.d_model = d_model\n",
    "    self.embedding = tf.keras.layers.Embedding(vocab_size, d_model, mask_zero=True)\n",
    "    self.pos_encoding = positional_encoding(length=2048, depth=d_model)\n",
    "\n",
    "  def compute_mask(self, *args, **kwargs):\n",
    "    return self.embedding.compute_mask(*args, **kwargs)\n",
    "\n",
    "  def call(self, x):\n",
    "    length = tf.shape(x)[1]\n",
    "    x = self.embedding(x)\n",
    "    # This factor sets the relative scale of the embedding and positonal_encoding.\n",
    "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "    x = x + self.pos_encoding[tf.newaxis, :length, :]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IdGErdpt-tZz",
    "outputId": "5cff902f-c186-47e5-f3c3-d21f968fcb71"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 256)\n",
      "(64, 256)\n",
      "(64, 256)\n",
      "tf.Tensor([ 64 256], shape=(2,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "for (wrong_sentence,correct_sentence), correct_sentence_labels in train_batches.take(1):\n",
    "  break\n",
    "print(wrong_sentence.shape)\n",
    "print(correct_sentence.shape)\n",
    "print(correct_sentence_labels.shape)\n",
    "print(tf.shape(wrong_sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "TBkFMfw4-9VE"
   },
   "outputs": [],
   "source": [
    "# print(wrong_sentence[0][:10])\n",
    "# print(correct_sentence_labels[0][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5syWSMLiC4Ls",
    "outputId": "cc1ae48f-a3a1-4bda-f35f-74acc755ee84"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 256, 512)\n"
     ]
    }
   ],
   "source": [
    "embed_wrong = PositionalEmbedding(vocab_size=len(vocab_to_int), d_model=512)\n",
    "embed_correct = PositionalEmbedding(vocab_size=len(vocab_to_int), d_model=512)\n",
    "\n",
    "wrong_emb = embed_wrong(wrong_sentence)\n",
    "correct_emb = embed_correct(correct_sentence)\n",
    "print(wrong_emb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "nNmFpNi_-qnI"
   },
   "outputs": [],
   "source": [
    "# correct_emb._keras_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "4G12SepD7PXL"
   },
   "outputs": [],
   "source": [
    "class BaseAttention(tf.keras.layers.Layer):\n",
    "  def __init__(self, **kwargs):\n",
    "    super().__init__()\n",
    "    self.mha = tf.keras.layers.MultiHeadAttention(**kwargs)\n",
    "    self.layernorm = tf.keras.layers.LayerNormalization()\n",
    "    self.add = tf.keras.layers.Add()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "p-1d0LMf8eTA"
   },
   "outputs": [],
   "source": [
    "class CrossAttention(BaseAttention):\n",
    "  def call(self, x, context):\n",
    "    attn_output, attn_scores = self.mha(\n",
    "        query=x,\n",
    "        key=context,\n",
    "        value=context,\n",
    "        return_attention_scores=True)\n",
    "\n",
    "    # Cache the attention scores for plotting later.\n",
    "    self.last_attn_scores = attn_scores\n",
    "\n",
    "    x = self.add([x, attn_output])\n",
    "    x = self.layernorm(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "lkGW93l9G6nW"
   },
   "outputs": [],
   "source": [
    "# sample_ca = CrossAttention(num_heads=2, key_dim=512)\n",
    "\n",
    "# print(wrong_emb.shape)\n",
    "# print(correct_emb.shape)\n",
    "# print(sample_ca(correct_emb, wrong_emb).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "4xSQBoMG8fR2"
   },
   "outputs": [],
   "source": [
    "class GlobalSelfAttention(BaseAttention):\n",
    "  def call(self, x):\n",
    "    attn_output = self.mha(\n",
    "        query=x,\n",
    "        value=x,\n",
    "        key=x)\n",
    "    x = self.add([x, attn_output])\n",
    "    x = self.layernorm(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "0JcerZizH2ma"
   },
   "outputs": [],
   "source": [
    "# sample_gsa = GlobalSelfAttention(num_heads=2, key_dim=512)\n",
    "\n",
    "# print(wrong_emb.shape)\n",
    "# print(sample_gsa(wrong_emb).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "2TNYIVqR9yss"
   },
   "outputs": [],
   "source": [
    "class CausalSelfAttention(BaseAttention):\n",
    "  def call(self, x):\n",
    "    attn_output = self.mha(\n",
    "        query=x,\n",
    "        value=x,\n",
    "        key=x,\n",
    "        use_causal_mask = True)\n",
    "    x = self.add([x, attn_output])\n",
    "    x = self.layernorm(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "TWVXSoRGIe2T"
   },
   "outputs": [],
   "source": [
    "# sample_csa = CausalSelfAttention(num_heads=2, key_dim=512)\n",
    "\n",
    "# print(correct_emb.shape)\n",
    "# print(sample_csa(correct_emb).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "gzeh5bqR_y8F"
   },
   "outputs": [],
   "source": [
    "class FeedForward(tf.keras.layers.Layer):\n",
    "  def __init__(self, d_model, dff, dropout_rate=0.1):\n",
    "    super().__init__()\n",
    "    self.seq = tf.keras.Sequential([\n",
    "      tf.keras.layers.Dense(dff, activation='relu'),\n",
    "      tf.keras.layers.Dense(d_model),\n",
    "      tf.keras.layers.Dropout(dropout_rate)\n",
    "    ])\n",
    "    self.add = tf.keras.layers.Add()\n",
    "    self.layer_norm = tf.keras.layers.LayerNormalization()\n",
    "\n",
    "  def call(self, x):\n",
    "    x = self.add([x, self.seq(x)])\n",
    "    x = self.layer_norm(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "-5u2_8KC_7js"
   },
   "outputs": [],
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "  def __init__(self,*, d_model, num_heads, dff, dropout_rate=0.1):\n",
    "    super().__init__()\n",
    "\n",
    "    self.self_attention = GlobalSelfAttention(\n",
    "        num_heads=num_heads,\n",
    "        key_dim=d_model,\n",
    "        dropout=dropout_rate)\n",
    "\n",
    "    self.ffn = FeedForward(d_model, dff)\n",
    "\n",
    "  def call(self, x):\n",
    "    x = self.self_attention(x)\n",
    "    x = self.ffn(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "7Gc0F6_0I0VB"
   },
   "outputs": [],
   "source": [
    "# sample_encoder_layer = EncoderLayer(d_model=512, num_heads=8, dff=2048)\n",
    "\n",
    "# print(wrong_emb.shape)\n",
    "# print(sample_encoder_layer(wrong_emb).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "O-afzG-zAGFH"
   },
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "  def __init__(self, *, num_layers, d_model, num_heads,\n",
    "               dff, vocab_size, dropout_rate=0.1):\n",
    "    super().__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.num_layers = num_layers\n",
    "\n",
    "    self.pos_embedding = PositionalEmbedding(\n",
    "        vocab_size=vocab_size, d_model=d_model)\n",
    "\n",
    "    self.enc_layers = [\n",
    "        EncoderLayer(d_model=d_model,\n",
    "                     num_heads=num_heads,\n",
    "                     dff=dff,\n",
    "                     dropout_rate=dropout_rate)\n",
    "        for _ in range(num_layers)]\n",
    "    self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
    "\n",
    "  def call(self, x):\n",
    "    # `x` is token-IDs shape: (batch, seq_len)\n",
    "    x = self.pos_embedding(x)  # Shape `(batch_size, seq_len, d_model)`.\n",
    "\n",
    "    # Add dropout.\n",
    "    x = self.dropout(x)\n",
    "\n",
    "    for i in range(self.num_layers):\n",
    "      x = self.enc_layers[i](x)\n",
    "\n",
    "    return x  # Shape `(batch_size, seq_len, d_model)`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "gU13yJSYCER2"
   },
   "outputs": [],
   "source": [
    "# sample_encoder = Encoder(num_layers=4,\n",
    "#                          d_model=512,\n",
    "#                          num_heads=8,\n",
    "#                          dff=2048,\n",
    "#                          vocab_size=len(vocab_to_int))\n",
    "\n",
    "# sample_encoder_output = sample_encoder(wrong_sentence, training=False)\n",
    "\n",
    "# # Print the shape.\n",
    "# print(wrong_sentence.shape)\n",
    "# print(sample_encoder_output.shape)  # Shape `(batch_size, input_seq_len, d_model)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "f58eAaa0Atem"
   },
   "outputs": [],
   "source": [
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "  def __init__(self,\n",
    "               *,\n",
    "               d_model,\n",
    "               num_heads,\n",
    "               dff,\n",
    "               dropout_rate=0.1):\n",
    "    super(DecoderLayer, self).__init__()\n",
    "\n",
    "    self.causal_self_attention = CausalSelfAttention(\n",
    "        num_heads=num_heads,\n",
    "        key_dim=d_model,\n",
    "        dropout=dropout_rate)\n",
    "\n",
    "    self.cross_attention = CrossAttention(\n",
    "        num_heads=num_heads,\n",
    "        key_dim=d_model,\n",
    "        dropout=dropout_rate)\n",
    "\n",
    "    self.ffn = FeedForward(d_model, dff)\n",
    "\n",
    "  def call(self, x, context):\n",
    "    x = self.causal_self_attention(x=x)\n",
    "    x = self.cross_attention(x=x, context=context)\n",
    "\n",
    "    # Cache the last attention scores for plotting later\n",
    "    self.last_attn_scores = self.cross_attention.last_attn_scores\n",
    "\n",
    "    x = self.ffn(x)  # Shape `(batch_size, seq_len, d_model)`.\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "DfVYusfIJp5K"
   },
   "outputs": [],
   "source": [
    "# sample_decoder_layer = DecoderLayer(d_model=512, num_heads=8, dff=2048)\n",
    "\n",
    "# sample_decoder_layer_output = sample_decoder_layer(\n",
    "#     x=correct_emb, context=wrong_emb)\n",
    "\n",
    "# print(correct_emb.shape)\n",
    "# print(wrong_emb.shape)\n",
    "# print(sample_decoder_layer_output.shape)  # `(batch_size, seq_len, d_model)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "iRmRXWvIAz_j"
   },
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.layers.Layer):\n",
    "  def __init__(self, *, num_layers, d_model, num_heads, dff, vocab_size,\n",
    "               dropout_rate=0.1):\n",
    "    super(Decoder, self).__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.num_layers = num_layers\n",
    "\n",
    "    self.pos_embedding = PositionalEmbedding(vocab_size=vocab_size,\n",
    "                                             d_model=d_model)\n",
    "    self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
    "    self.dec_layers = [\n",
    "        DecoderLayer(d_model=d_model, num_heads=num_heads,\n",
    "                     dff=dff, dropout_rate=dropout_rate)\n",
    "        for _ in range(num_layers)]\n",
    "\n",
    "    self.last_attn_scores = None\n",
    "\n",
    "  def call(self, x, context):\n",
    "    # `x` is token-IDs shape (batch, target_seq_len)\n",
    "    x = self.pos_embedding(x)  # (batch_size, target_seq_len, d_model)\n",
    "\n",
    "    x = self.dropout(x)\n",
    "\n",
    "    for i in range(self.num_layers):\n",
    "      x  = self.dec_layers[i](x, context)\n",
    "\n",
    "    self.last_attn_scores = self.dec_layers[-1].last_attn_scores\n",
    "\n",
    "    # The shape of x is (batch_size, target_seq_len, d_model).\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "U7a3tO6LJ_jp"
   },
   "outputs": [],
   "source": [
    "# # Instantiate the decoder.\n",
    "# sample_decoder = Decoder(num_layers=4,\n",
    "#                          d_model=512,\n",
    "#                          num_heads=8,\n",
    "#                          dff=2048,\n",
    "#                          vocab_size=len(vocab_to_int))\n",
    "\n",
    "# output = sample_decoder(\n",
    "#     x=correct_sentence,\n",
    "#     context=wrong_emb)\n",
    "\n",
    "# # Print the shapes.\n",
    "# print(correct_sentence.shape)\n",
    "# print(wrong_emb.shape)\n",
    "# print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "sZ9DEd9gKpZ5"
   },
   "outputs": [],
   "source": [
    "# sample_decoder.last_attn_scores.shape  # (batch, heads, target_seq, input_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "fWpVS0R1A2Q-"
   },
   "outputs": [],
   "source": [
    "class Transformer(tf.keras.Model):\n",
    "  def __init__(self, *, num_layers, d_model, num_heads, dff,\n",
    "               input_vocab_size, target_vocab_size, dropout_rate=0.1):\n",
    "    super().__init__()\n",
    "    self.encoder = Encoder(num_layers=num_layers, d_model=d_model,\n",
    "                           num_heads=num_heads, dff=dff,\n",
    "                           vocab_size=input_vocab_size,\n",
    "                           dropout_rate=dropout_rate)\n",
    "\n",
    "    self.decoder = Decoder(num_layers=num_layers, d_model=d_model,\n",
    "                           num_heads=num_heads, dff=dff,\n",
    "                           vocab_size=target_vocab_size,\n",
    "                           dropout_rate=dropout_rate)\n",
    "\n",
    "    self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
    "\n",
    "  def call(self, inputs):\n",
    "    # To use a Keras model with `.fit` you must pass all your inputs in the\n",
    "    # first argument.\n",
    "    context, x  = inputs\n",
    "\n",
    "    context = self.encoder(context)  # (batch_size, context_len, d_model)\n",
    "\n",
    "    x = self.decoder(x, context)  # (batch_size, target_len, d_model)\n",
    "\n",
    "    # Final linear layer output.\n",
    "    logits = self.final_layer(x)  # (batch_size, target_len, target_vocab_size)\n",
    "\n",
    "    try:\n",
    "      # Drop the keras mask, so it doesn't scale the losses/metrics.\n",
    "      # b/250038731\n",
    "      del logits._keras_mask\n",
    "    except AttributeError:\n",
    "      pass\n",
    "\n",
    "    # Return the final output and the attention weights.\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "7Xk_VsjcBm4Z"
   },
   "outputs": [],
   "source": [
    "num_layers = 4\n",
    "d_model = 128\n",
    "dff = 512\n",
    "num_heads = 8\n",
    "dropout_rate = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "8cu56QXiQFvr"
   },
   "outputs": [],
   "source": [
    "transformer = Transformer(\n",
    "    num_layers=num_layers,\n",
    "    d_model=d_model,\n",
    "    num_heads=num_heads,\n",
    "    dff=dff,\n",
    "    input_vocab_size=len(vocab_to_int),\n",
    "    target_vocab_size=len(vocab_to_int),\n",
    "    dropout_rate=dropout_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "2_1F1XfKK4Jb"
   },
   "outputs": [],
   "source": [
    "# output = transformer((wrong_sentence, correct_sentence))\n",
    "\n",
    "# print(correct_sentence.shape)\n",
    "# print(wrong_sentence.shape)\n",
    "# print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "g33heYNuMrnh"
   },
   "outputs": [],
   "source": [
    "# attn_scores = transformer.decoder.dec_layers[-1].last_attn_scores\n",
    "# print(attn_scores.shape)  # (batch, heads, target_seq, input_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "UsrJTkNZMuyv"
   },
   "outputs": [],
   "source": [
    "# transformer.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "PrrV0G4qB2rh"
   },
   "outputs": [],
   "source": [
    "transformer = Transformer(\n",
    "    num_layers=num_layers,\n",
    "    d_model=d_model,\n",
    "    num_heads=num_heads,\n",
    "    dff=dff,\n",
    "    input_vocab_size=len(vocab_to_int),\n",
    "    target_vocab_size=len(vocab_to_int),\n",
    "    dropout_rate=dropout_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "yCIAmc3XB60w"
   },
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "  def __init__(self, d_model, warmup_steps=4000):\n",
    "    super().__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "    self.warmup_steps = warmup_steps\n",
    "\n",
    "  def __call__(self, step):\n",
    "    step = tf.cast(step, dtype=tf.float32)\n",
    "    arg1 = tf.math.rsqrt(step)\n",
    "    arg2 = step * (self.warmup_steps ** -1.5)\n",
    "\n",
    "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "A9xusyZUCpXx"
   },
   "outputs": [],
   "source": [
    "learning_rate = CustomSchedule(d_model)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98,\n",
    "                                     epsilon=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 466
    },
    "id": "3O7UI3zlCvDK",
    "outputId": "10cb5275-b3ad-4c59-b023-ee824298a390"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Train Step')"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(learning_rate(tf.range(40000, dtype=tf.float32)))\n",
    "plt.ylabel('Learning Rate')\n",
    "plt.xlabel('Train Step')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "qW4E5DqaC9SK"
   },
   "outputs": [],
   "source": [
    "def masked_loss(label, pred):\n",
    "  mask = label != 0\n",
    "  loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "  loss = loss_object(label, pred)\n",
    "\n",
    "  mask = tf.cast(mask, dtype=loss.dtype)\n",
    "  loss *= mask\n",
    "\n",
    "  loss = tf.reduce_sum(loss)/tf.reduce_sum(mask)\n",
    "  return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "095iqf2KC-GP"
   },
   "outputs": [],
   "source": [
    "def masked_accuracy(label, pred):\n",
    "  pred = tf.argmax(pred, axis=2)\n",
    "  label = tf.cast(label, pred.dtype)\n",
    "  match = label == pred\n",
    "\n",
    "  mask = label != 0\n",
    "\n",
    "  match = match & mask\n",
    "\n",
    "  match = tf.cast(match, dtype=tf.float32)\n",
    "  mask = tf.cast(mask, dtype=tf.float32)\n",
    "  return tf.reduce_sum(match)/tf.reduce_sum(mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "4zLVzNcpDIL4"
   },
   "outputs": [],
   "source": [
    "transformer.compile(\n",
    "    loss=masked_loss,\n",
    "    optimizer=optimizer,\n",
    "    metrics=[masked_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z9VSkwuUDM4j",
    "outputId": "9495fc7e-6e2b-4986-fb9a-ac6337353dc0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'query' (of type EinsumDense) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'key' (of type EinsumDense) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'value' (of type EinsumDense) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'global_self_attention_4' (of type GlobalSelfAttention) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'sequential_8' (of type Sequential) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'feed_forward_8' (of type FeedForward) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'encoder_layer_4' (of type EncoderLayer) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'global_self_attention_5' (of type GlobalSelfAttention) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'sequential_9' (of type Sequential) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'feed_forward_9' (of type FeedForward) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'encoder_layer_5' (of type EncoderLayer) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'global_self_attention_6' (of type GlobalSelfAttention) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'sequential_10' (of type Sequential) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'feed_forward_10' (of type FeedForward) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'encoder_layer_6' (of type EncoderLayer) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'global_self_attention_7' (of type GlobalSelfAttention) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'sequential_11' (of type Sequential) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'feed_forward_11' (of type FeedForward) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'encoder_layer_7' (of type EncoderLayer) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'causal_self_attention_4' (of type CausalSelfAttention) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'cross_attention_4' (of type CrossAttention) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'sequential_12' (of type Sequential) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'feed_forward_12' (of type FeedForward) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'decoder_layer_4' (of type DecoderLayer) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'causal_self_attention_5' (of type CausalSelfAttention) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'cross_attention_5' (of type CrossAttention) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'sequential_13' (of type Sequential) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'feed_forward_13' (of type FeedForward) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'decoder_layer_5' (of type DecoderLayer) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'causal_self_attention_6' (of type CausalSelfAttention) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'cross_attention_6' (of type CrossAttention) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'sequential_14' (of type Sequential) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'feed_forward_14' (of type FeedForward) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'decoder_layer_6' (of type DecoderLayer) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'causal_self_attention_7' (of type CausalSelfAttention) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'cross_attention_7' (of type CrossAttention) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'sequential_15' (of type Sequential) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'feed_forward_15' (of type FeedForward) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'decoder_layer_7' (of type DecoderLayer) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 1s/step - loss: 8.9908 - masked_accuracy: 0.0025 - val_loss: 8.8105 - val_masked_accuracy: 0.0472\n",
      "Epoch 2/30\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 628ms/step - loss: 8.7508 - masked_accuracy: 0.0469 - val_loss: 8.5610 - val_masked_accuracy: 0.0544\n",
      "Epoch 3/30\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 597ms/step - loss: 8.4826 - masked_accuracy: 0.0640 - val_loss: 8.1969 - val_masked_accuracy: 0.0813\n",
      "Epoch 4/30\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 588ms/step - loss: 8.0920 - masked_accuracy: 0.0855 - val_loss: 7.7518 - val_masked_accuracy: 0.0956\n",
      "Epoch 5/30\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 595ms/step - loss: 7.6334 - masked_accuracy: 0.1001 - val_loss: 7.2886 - val_masked_accuracy: 0.1067\n",
      "Epoch 6/30\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 628ms/step - loss: 7.1719 - masked_accuracy: 0.1128 - val_loss: 6.8651 - val_masked_accuracy: 0.1237\n",
      "Epoch 7/30\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 595ms/step - loss: 6.7592 - masked_accuracy: 0.1300 - val_loss: 6.5047 - val_masked_accuracy: 0.1536\n",
      "Epoch 8/30\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 591ms/step - loss: 6.4050 - masked_accuracy: 0.1635 - val_loss: 6.1402 - val_masked_accuracy: 0.1987\n",
      "Epoch 9/30\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 601ms/step - loss: 6.0330 - masked_accuracy: 0.2013 - val_loss: 5.7381 - val_masked_accuracy: 0.2264\n",
      "Epoch 10/30\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 592ms/step - loss: 5.5827 - masked_accuracy: 0.2363 - val_loss: 5.3087 - val_masked_accuracy: 0.2515\n",
      "Epoch 11/30\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 588ms/step - loss: 5.1353 - masked_accuracy: 0.2735 - val_loss: 4.8485 - val_masked_accuracy: 0.2951\n",
      "Epoch 12/30\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 592ms/step - loss: 4.6568 - masked_accuracy: 0.3209 - val_loss: 4.4059 - val_masked_accuracy: 0.3738\n",
      "Epoch 13/30\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 593ms/step - loss: 4.1339 - masked_accuracy: 0.3839 - val_loss: 3.9431 - val_masked_accuracy: 0.4406\n",
      "Epoch 14/30\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 593ms/step - loss: 3.6867 - masked_accuracy: 0.4480 - val_loss: 3.5128 - val_masked_accuracy: 0.4873\n",
      "Epoch 15/30\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 592ms/step - loss: 3.2166 - masked_accuracy: 0.5188 - val_loss: 3.1094 - val_masked_accuracy: 0.5594\n",
      "Epoch 16/30\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 634ms/step - loss: 2.7471 - masked_accuracy: 0.5968 - val_loss: 2.7530 - val_masked_accuracy: 0.6104\n",
      "Epoch 17/30\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 587ms/step - loss: 2.3655 - masked_accuracy: 0.6534 - val_loss: 2.3836 - val_masked_accuracy: 0.6774\n",
      "Epoch 18/30\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 593ms/step - loss: 1.9593 - masked_accuracy: 0.7175 - val_loss: 2.0885 - val_masked_accuracy: 0.7161\n",
      "Epoch 19/30\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 588ms/step - loss: 1.6267 - masked_accuracy: 0.7638 - val_loss: 1.8620 - val_masked_accuracy: 0.7492\n",
      "Epoch 20/30\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 597ms/step - loss: 1.3710 - masked_accuracy: 0.8020 - val_loss: 1.6676 - val_masked_accuracy: 0.7763\n",
      "Epoch 21/30\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 593ms/step - loss: 1.1055 - masked_accuracy: 0.8427 - val_loss: 1.5057 - val_masked_accuracy: 0.8008\n",
      "Epoch 22/30\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 594ms/step - loss: 0.9110 - masked_accuracy: 0.8724 - val_loss: 1.3369 - val_masked_accuracy: 0.8240\n",
      "Epoch 23/30\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 595ms/step - loss: 0.7373 - masked_accuracy: 0.8981 - val_loss: 1.2681 - val_masked_accuracy: 0.8310\n",
      "Epoch 24/30\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 589ms/step - loss: 0.6317 - masked_accuracy: 0.9146 - val_loss: 1.1145 - val_masked_accuracy: 0.8598\n",
      "Epoch 25/30\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 590ms/step - loss: 0.4918 - masked_accuracy: 0.9364 - val_loss: 1.0562 - val_masked_accuracy: 0.8683\n",
      "Epoch 26/30\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 634ms/step - loss: 0.3976 - masked_accuracy: 0.9481 - val_loss: 1.0031 - val_masked_accuracy: 0.8740\n",
      "Epoch 27/30\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 592ms/step - loss: 0.3375 - masked_accuracy: 0.9545 - val_loss: 0.9543 - val_masked_accuracy: 0.8787\n",
      "Epoch 28/30\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 593ms/step - loss: 0.2734 - masked_accuracy: 0.9621 - val_loss: 0.9230 - val_masked_accuracy: 0.8849\n",
      "Epoch 29/30\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 593ms/step - loss: 0.2386 - masked_accuracy: 0.9667 - val_loss: 0.8519 - val_masked_accuracy: 0.8957\n",
      "Epoch 30/30\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 634ms/step - loss: 0.1910 - masked_accuracy: 0.9713 - val_loss: 0.8596 - val_masked_accuracy: 0.8964\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x78edd1a76e00>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer.fit(train_batches,\n",
    "                epochs=30,\n",
    "                validation_data=val_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "id": "Gb5xNRGnDOMI"
   },
   "outputs": [],
   "source": [
    "class Spell_correction(tf.Module):\n",
    "  def __init__(self, tokenizers, transformer):\n",
    "    self.tokenizers = tokenizers\n",
    "    self.transformer = transformer\n",
    "\n",
    "  def __call__(self, sentence, max_length=MAX_TOKENS):\n",
    "    # print(sentence.shape)\n",
    "    # The input sentence is Portuguese, hence adding the `[START]` and `[END]` tokens.\n",
    "    # assert isinstance(sentence, tf.Tensor)\n",
    "    # if len(sentence.shape) == 0:\n",
    "    #   sentence = sentence[tf.newaxis]\n",
    "    x=self.tokenizers(sentence)\n",
    "    x_1=tf.keras.preprocessing.sequence.pad_sequences([x],maxlen=256 ,padding='post', value=vocab_to_int[\"<PAD>\"],truncating='post')\n",
    "\n",
    "    sentence =tf.convert_to_tensor( x_1,dtype=tf.int64)\n",
    "    encoder_input = sentence\n",
    "\n",
    "    # As the output language is English, initialize the output with the\n",
    "    # English `[START]` token.\n",
    "    # start_end = self.tokenizers.en.tokenize([''])[0]\n",
    "    # start = start_end[0][tf.newaxis]\n",
    "    # end = start_end[1][tf.newaxis]\n",
    "\n",
    "    list_temp=[]\n",
    "    list_temp.append(vocab_to_int['<sos>'])\n",
    "    start=tf.constant(list_temp,dtype=tf.int64)\n",
    "    list_temp=[]\n",
    "    list_temp.append(vocab_to_int['<eos>'])\n",
    "    end=tf.constant(list_temp,dtype=tf.int64)\n",
    "    # `tf.TensorArray` is required here (instead of a Python list), so that the\n",
    "    # dynamic-loop can be traced by `tf.function`.\n",
    "    output_array = tf.TensorArray(dtype=tf.int64, size=0, dynamic_size=True)\n",
    "    output_array = output_array.write(0, start)\n",
    "    # print(output_array.shape)\n",
    "    for i in tf.range(max_length):\n",
    "\n",
    "      output = tf.transpose(output_array.stack())\n",
    "      predictions = self.transformer([encoder_input, output], training=False)\n",
    "\n",
    "      # Select the last token from the `seq_len` dimension.\n",
    "      predictions = predictions[:, -1:, :]  # Shape `(batch_size, 1, vocab_size)`.\n",
    "\n",
    "      predicted_id = tf.argmax(predictions, axis=-1)\n",
    "\n",
    "      # Concatenate the `predicted_id` to the output which is given to the\n",
    "      # decoder as its input.\n",
    "      output_array = output_array.write(i+1, predicted_id[0])\n",
    "\n",
    "      if predicted_id == end:\n",
    "        break\n",
    "\n",
    "    output = tf.transpose(output_array.stack())\n",
    "    # The output shape is `(1, tokens)`.\n",
    "    # text = tokenizers.en.detokenize(output)[0]  # Shape: `()`.\n",
    "\n",
    "    # tokens = tokenizers.en.lookup(output)[0]\n",
    "    text=detokenizer(output.numpy().tolist()[0])\n",
    "    # Return the tokens\n",
    "    tokens=[]\n",
    "    for num in output.numpy().tolist()[0]:\n",
    "      tokens.append(int_to_vocab[num])\n",
    "    # `tf.function` prevents us from using the attention_weights that were\n",
    "    # calculated on the last iteration of the loop.\n",
    "    # So, recalculate them outside the loop.\n",
    "    self.transformer([encoder_input, output[:,:-1]], training=False)\n",
    "    attention_weights = self.transformer.decoder.last_attn_scores\n",
    "\n",
    "    return text,tokens, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "SgK2-hKmskuI"
   },
   "outputs": [],
   "source": [
    "def print_correction(sentence, tokens, ground_truth):\n",
    "  print(f'{\"Input:\":15s}: {sentence}')\n",
    "  print(f'{\"Prediction\":15s}: {tokens}')\n",
    "  print(f'{\"Ground truth\":15s}: {ground_truth}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "id": "ScPwxwE0Q4Yq"
   },
   "outputs": [],
   "source": [
    "spell_corrector = Spell_correction(tokenizer, transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WH5MtY9LPtiS",
    "outputId": "712dc3d5-6df6-4fd2-df80-20cf2a4e6315"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'query' (of type EinsumDense) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'key' (of type EinsumDense) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'value' (of type EinsumDense) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'global_self_attention_4' (of type GlobalSelfAttention) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'sequential_8' (of type Sequential) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'feed_forward_8' (of type FeedForward) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'encoder_layer_4' (of type EncoderLayer) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'global_self_attention_5' (of type GlobalSelfAttention) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'sequential_9' (of type Sequential) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'feed_forward_9' (of type FeedForward) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'encoder_layer_5' (of type EncoderLayer) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'global_self_attention_6' (of type GlobalSelfAttention) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'sequential_10' (of type Sequential) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'feed_forward_10' (of type FeedForward) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'encoder_layer_6' (of type EncoderLayer) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'global_self_attention_7' (of type GlobalSelfAttention) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'sequential_11' (of type Sequential) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'feed_forward_11' (of type FeedForward) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'encoder_layer_7' (of type EncoderLayer) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/keras/src/ops/nn.py:545: UserWarning: You are using a softmax over axis 3 of a tensor of shape (1, 8, 1, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'causal_self_attention_4' (of type CausalSelfAttention) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'cross_attention_4' (of type CrossAttention) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'sequential_12' (of type Sequential) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'feed_forward_12' (of type FeedForward) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'decoder_layer_4' (of type DecoderLayer) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'causal_self_attention_5' (of type CausalSelfAttention) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'cross_attention_5' (of type CrossAttention) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'sequential_13' (of type Sequential) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'feed_forward_13' (of type FeedForward) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'decoder_layer_5' (of type DecoderLayer) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'causal_self_attention_6' (of type CausalSelfAttention) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'cross_attention_6' (of type CrossAttention) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'sequential_14' (of type Sequential) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'feed_forward_14' (of type FeedForward) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'decoder_layer_6' (of type DecoderLayer) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'causal_self_attention_7' (of type CausalSelfAttention) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'cross_attention_7' (of type CrossAttention) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'sequential_15' (of type Sequential) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'feed_forward_15' (of type FeedForward) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'decoder_layer_7' (of type DecoderLayer) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:         : دیوار کلاس سفد است\n",
      "Prediction     : <sos> دیوار کلاس سفید است <eos> \n",
      "Ground truth   : دیوار کلاس سفید است\n"
     ]
    }
   ],
   "source": [
    "input= \"دیوار کلاس سفد است\"\n",
    "ground_truth=\"دیوار کلاس سفید است\"\n",
    "\n",
    "\n",
    "\n",
    "translated_text, translated_tokens, attention_weights = spell_corrector(\n",
    "    input)\n",
    "print_translation(input, translated_text, ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "id": "6NWlVkz9ZIp_"
   },
   "outputs": [],
   "source": [
    "tf.config.run_functions_eagerly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "id": "51xovQiR_OG7"
   },
   "outputs": [],
   "source": [
    "class ExportSpellCorrector(tf.Module):\n",
    "  def __init__(self, spell_corrector):\n",
    "    self.spell_corrector = spell_corrector\n",
    "\n",
    "  @tf.function\n",
    "  def __call__(self, sentence):\n",
    "    (result,\n",
    "     tokens,\n",
    "     attention_weights) = self.spell_corrector(sentence, max_length=MAX_TOKENS)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "id": "D5Bo29YdZ7_5"
   },
   "outputs": [],
   "source": [
    "spell_corrector = ExportSpellCorrector(spell_corrector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "B-MykFRas7eE",
    "outputId": "851aa878-510d-4029-d5e5-b7196df188ed"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'<sos> دیوار کلاس سفید است <eos> '"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spell_corrector(\"دیوار کلاس سفد است\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "id": "0NoD37yOs9qq"
   },
   "outputs": [],
   "source": [
    "tf.saved_model.save(spell_corrector, export_dir='/content/drive/MyDrive/Spell_correction/saved_model')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
