{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o5kKlVH0LRe-",
        "outputId": "798f242b-382e-4b2e-8ef2-f3aac2f3f059"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: hazm in /usr/local/lib/python3.10/dist-packages (0.10.0)\n",
            "Requirement already satisfied: fasttext-wheel<0.10.0,>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from hazm) (0.9.2)\n",
            "Requirement already satisfied: flashtext<3.0,>=2.7 in /usr/local/lib/python3.10/dist-packages (from hazm) (2.7)\n",
            "Requirement already satisfied: gensim<5.0.0,>=4.3.1 in /usr/local/lib/python3.10/dist-packages (from hazm) (4.3.3)\n",
            "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /usr/local/lib/python3.10/dist-packages (from hazm) (3.8.1)\n",
            "Requirement already satisfied: numpy==1.24.3 in /usr/local/lib/python3.10/dist-packages (from hazm) (1.24.3)\n",
            "Requirement already satisfied: python-crfsuite<0.10.0,>=0.9.9 in /usr/local/lib/python3.10/dist-packages (from hazm) (0.9.10)\n",
            "Requirement already satisfied: scikit-learn<2.0.0,>=1.2.2 in /usr/local/lib/python3.10/dist-packages (from hazm) (1.3.2)\n",
            "Requirement already satisfied: pybind11>=2.2 in /usr/local/lib/python3.10/dist-packages (from fasttext-wheel<0.10.0,>=0.9.2->hazm) (2.13.4)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from fasttext-wheel<0.10.0,>=0.9.2->hazm) (71.0.4)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim<5.0.0,>=4.3.1->hazm) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim<5.0.0,>=4.3.1->hazm) (7.0.4)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->hazm) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->hazm) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->hazm) (2024.5.15)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->hazm) (4.66.5)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<2.0.0,>=1.2.2->hazm) (3.5.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open>=1.8.1->gensim<5.0.0,>=4.3.1->hazm) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install hazm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "B94kr-7NCeg_"
      },
      "outputs": [],
      "source": [
        "import logging\n",
        "import time\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "from hazm import word_tokenize\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-RWQ_yBqKrED",
        "outputId": "88ac8147-7328-40b9-c119-05319a7a92c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "B5MTNdxnKrAk"
      },
      "outputs": [],
      "source": [
        "df=pd.read_csv(\"/content/drive/MyDrive/Spell_correction/data.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8RYrrEVNybIy"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "L1QdGI5EKjO9"
      },
      "outputs": [],
      "source": [
        "# df=df[df[\"main_category\"]==\"Main signs\" ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "qWrWf-i0Kq-P"
      },
      "outputs": [],
      "source": [
        "df=df[[\"wrong_sentence\",\"correct_sentence\"]]\n",
        "df=df.dropna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "12PEhzyzNPMz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3a0205c-f862-4626-ad30-5af644dee843"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9205"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "len(df)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "_q-QlmZgzH_-",
        "outputId": "82cc205b-f278-40fe-8306-8cdb41b39f25"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                      wrong_sentence  \\\n",
              "0  افغانستان\\n \\n موضوع : اسراف\\n \\n اسراف را خدا...   \n",
              "1  افغانستان\\n \\n موضوع : اسراف\\n \\n اسراف را خدا...   \n",
              "2  افغانستان\\n \\n موضوع : اسراف\\n \\n اسراف را خدا...   \n",
              "3  افغانستان\\n \\n موضوع : اسراف\\n \\n اسراف را خدا...   \n",
              "4  افغانستان\\n \\n موضوع : اسراف\\n \\n اسراف را خدا...   \n",
              "\n",
              "                                    correct_sentence  \n",
              "0  افغانستان\\n \\n موضوع : اسراف\\n \\n اسراف را خدا...  \n",
              "1  افغانستان\\n \\n موضوع : اسراف\\n \\n اسراف را خدا...  \n",
              "2  افغانستان\\n \\n موضوع : اسراف\\n \\n اسراف را خدا...  \n",
              "3  افغانستان\\n \\n موضوع : اسراف\\n \\n اسراف را خدا...  \n",
              "4  افغانستان\\n \\n موضوع : اسراف\\n \\n اسراف را خدا...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e7d354da-5688-438a-954a-fdd23da894e7\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>wrong_sentence</th>\n",
              "      <th>correct_sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>افغانستان\\n \\n موضوع : اسراف\\n \\n اسراف را خدا...</td>\n",
              "      <td>افغانستان\\n \\n موضوع : اسراف\\n \\n اسراف را خدا...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>افغانستان\\n \\n موضوع : اسراف\\n \\n اسراف را خدا...</td>\n",
              "      <td>افغانستان\\n \\n موضوع : اسراف\\n \\n اسراف را خدا...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>افغانستان\\n \\n موضوع : اسراف\\n \\n اسراف را خدا...</td>\n",
              "      <td>افغانستان\\n \\n موضوع : اسراف\\n \\n اسراف را خدا...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>افغانستان\\n \\n موضوع : اسراف\\n \\n اسراف را خدا...</td>\n",
              "      <td>افغانستان\\n \\n موضوع : اسراف\\n \\n اسراف را خدا...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>افغانستان\\n \\n موضوع : اسراف\\n \\n اسراف را خدا...</td>\n",
              "      <td>افغانستان\\n \\n موضوع : اسراف\\n \\n اسراف را خدا...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e7d354da-5688-438a-954a-fdd23da894e7')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e7d354da-5688-438a-954a-fdd23da894e7 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e7d354da-5688-438a-954a-fdd23da894e7');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-3cfda778-c992-494b-8f0c-cadd6437c7a0\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3cfda778-c992-494b-8f0c-cadd6437c7a0')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-3cfda778-c992-494b-8f0c-cadd6437c7a0 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 9205,\n  \"fields\": [\n    {\n      \"column\": \"wrong_sentence\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3438,\n        \"samples\": [\n          \"\\u0633\\u0627\\u0639\\u062a \\u062f\\u0648 \\u062a\\u0627 \\u0633\\u0627\\u0639\\u062a \\u0633\\u0647 \\u0646\\u0642\\u0627\\u0634\\u0647 \\u0645\\u06cc \\u06a9\\u0634\\u0645 \\u0648 \\u0633\\u0627\\u0639\\u062a \\u0633\\u0647 \\u0648 \\u0646\\u06cc\\u0645 \\u062a\\u0627 \\u0633\\u0627\\u0639\\u062a \\u0634\\u0634 \\u0645\\u0646 \\u062a\\u06a9\\u0644\\u06cc\\u0641 \\u0645\\u06cc \\u0646\\u0648\\u06cc\\u0633\\u0645 \\u0648 \\u0645\\u0637\\u0644\\u0639\\u0647 \\u0645\\u06cc \\u06a9\\u0646\\u0645 .\",\n          \"\\u0641\\u0635\\u0644 \\u0628\\u0647\\u0627\\u0631 3 \\u0645\\u0627\\u0647 \\u062f\\u0627\\u0631\\u062f \\u060c \\u0627\\u0633\\u0645 \\u0647\\u0627\\u06cc\\u0634\\u0627\\u0646 \\u0641\\u0631\\u0648\\u0631\\u062f\\u06cc\\u0646 \\u060c \\u0627\\u0648\\u062f\\u06cc\\u0628\\u0647\\u0634\\u062a \\u060c \\u062e\\u0631\\u062f\\u0627\\u062f\\n \\n \\u0641\\u0635\\u0644 \\u0628\\u0647\\u0627\\u0631 \\u0627\\u0648\\u0651\\u0644 \\u0645\\u0627\\u0647 \\u0627\\u0633\\u062a .\",\n          \"\\u0646\\u0648\\u06cc\\u0633\\u0646\\u062f\\u06c0 \\u0631\\u0648\\u0632\\u0646\\u0627\\u0645\\u0647 \\u0646\\u0648\\u0634\\u062a \\u06a9\\u0647 \\u0627\\u0631\\u062f\\u0648\\u063a\\u0627\\u0646 \\u0648 \\u062d\\u06a9\\u0648\\u0645\\u062a\\u0634 \\u062d\\u0627\\u0644\\u0627 \\u0628\\u0627\\u06cc\\u062f \\u062a\\u0641\\u06a9\\u0631\\u0634\\u0627\\u0646 \\u0639\\u0648\\u0636 \\u06a9\\u0646\\u0646\\u062f \\u062a\\u0627 \\u0627\\u06cc\\u0646\\u06a9\\u0647 \\u0628\\u062a\\u0648\\u0627\\u0646\\u0646\\u062f \\u06af\\u0641\\u062a\\u06af\\u0648 \\u0627\\u06cc \\u0628\\u0627 \\u062d\\u0632\\u0628 \\u0647 .\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"correct_sentence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 8331,\n        \"samples\": [\n          \"\\u067e\\u0633 \\u0686\\u0648\\u0646\\u0646 \\u062f\\u0627\\u0646\\u06cc\\u0634\\u062e\\u0648\\u06cc\\u0627\\u0646 \\u0628\\u0627 \\u0647\\u0645 \\u062f\\u06af\\u0631 \\u0645\\u0648\\u0646\\u0627\\u0633\\u0628\\u062a \\u0645\\u06cc\\u06a9\\u0648\\u0646\\u0646\\u062f \\u060c \\u06af\\u0648\\u0641\\u062a\\u06af\\u0648 \\u0645\\u06cc\\u06a9\\u0648\\u0646\\u0646\\u062f \\u060c \\u0628\\u062d\\u0633\\u0648 \\u0645\\u0648\\u0646\\u0627\\u0631\\u062f\\u0647 \\u0645\\u06cc\\u06a9\\u0648\\u0646\\u0646\\u062f \\u060c \\u0627\\u0632 \\u0647\\u0645 \\u062f\\u06af\\u0631 \\u0645\\u06cc\\u067e\\u0648\\u0631\\u0633\\u0646\\u062f .\",\n          \"\\u062f\\u0631 \\u0645\\u062f\\u0631\\u0633\\u0647 \\u06cc \\u0645\\u0646 \\u0645\\u0647\\u062f\\u06cc \\u06a9\\u0648\\u062f\\u06a9 \\u0627\\u0633\\u062a .\",\n          \"\\u0634\\u0645\\u0627 \\u062e\\u0648\\u0631\\u062f\\u0645 \\u0648 \\u0646\\u0645\\u0627\\u0632 \\u0634\\u0628 \\u0645\\u06cc \\u062e\\u0648\\u0627\\u0646\\u0645 \\u0628\\u0639\\u062f \\u062f\\u0648\\u0628\\u0627\\u0631\\u0647 \\u062f\\u0648 \\u0633\\u0627\\u0639\\u062a \\u0645\\u0637\\u0644\\u0627\\u06cc \\u06a9\\u0631\\u062f\\u0646\\u062f \\u0645\\u0646 \\u0648 \\u0647\\u0645\\u0633\\u0631\\u0645 \\u06cc\\u06a9 \\u0633\\u0627\\u0639\\u062a \\u0627\\u0645\\u0644\\u0627 \\u062a\\u06a9\\u0631\\u0627\\u0631 \\u06a9\\u0631\\u062f\\u06cc\\u0645 \\u0628\\u0639\\u062f \\u062d\\u0648\\u0628\\u06cc \\u062f\\u06cc\\u0645 .\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "SG4Ep-C6Kq5Y"
      },
      "outputs": [],
      "source": [
        "#create vocabulay\n",
        "symbols_to_remove = ['@', '#', '$', '%', '^', '&', '*', '(', ')','[',']','{','}','\"','*\\r','+',',','ø','>>','CV','EXPO','None','alfare','fat','«','0-9','\\\\u200','\\\\u200c','\\\\u200f','\\\\u200e']\n",
        "# Create a regex pattern that matches any of the symbols in the list\n",
        "pattern = re.compile(f\"[{re.escape(''.join(symbols_to_remove))}]\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "l5sIXcS4MiJN"
      },
      "outputs": [],
      "source": [
        "# create a dictionary to convert the vocabulary to integers\n",
        "vocab_to_int = {}\n",
        "count = 0\n",
        "#tokenize and put <start> , < end >\n",
        "# Add special tokens to vocab_to_int\n",
        "codes = ['<PAD>','<eos>','<sos>','<UNK>']\n",
        "for code in codes:\n",
        "    vocab_to_int[code] = count\n",
        "    count += 1\n",
        "\n",
        "for index in df.index:\n",
        "    for word in word_tokenize(df.at[index,\"wrong_sentence\"]):\n",
        "        cleaned_string = pattern.sub(\"\", word)\n",
        "        # cleaned_string = new_word.replace(\"\\u200c\", \"\").replace(\"\\u200f\", \"\")\n",
        "        if cleaned_string not in vocab_to_int:\n",
        "            vocab_to_int[cleaned_string] = count\n",
        "            count += 1\n",
        "    for word in word_tokenize(df.at[index,\"correct_sentence\"]):\n",
        "        cleaned_string = pattern.sub(\"\", word)\n",
        "        # cleaned_string = new_word.replace(\"\\u200c\", \"\").replace(\"\\u200f\", \"\")\n",
        "        if cleaned_string not in vocab_to_int:\n",
        "            vocab_to_int[cleaned_string] = count\n",
        "            count += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "a64Tv7QSKq8u"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FGZsZqTPNdc2",
        "outputId": "97a11053-06c6-45f4-cf09-0f09acfcc2dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The vocabulary contains 9686 words.\n"
          ]
        }
      ],
      "source": [
        "vocab_size = len(vocab_to_int)\n",
        "print(\"The vocabulary contains {} words.\".format(vocab_size))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "T6_eq3Z6Ngl9"
      },
      "outputs": [],
      "source": [
        "# Create another dictionary to convert integers to their respective characters\n",
        "int_to_vocab = {}\n",
        "for word, value in vocab_to_int.items():\n",
        "    int_to_vocab[value] = word"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(\n",
        "    df['correct_sentence'], target_vocab_size=len(vocab_to_int))"
      ],
      "metadata": {
        "id": "pxesL1_Cu7QL"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example text\n",
        "text = \"زبان فارسی زیبا است.\"\n",
        "\n",
        "# Encode the text\n",
        "encoded = tokenizer.encode(text)\n",
        "print(\"Encoded:\", encoded)\n",
        "\n",
        "# Decode the subwords back to the original text\n",
        "decoded = tokenizer.decode(encoded)\n",
        "print(\"Decoded:\", decoded)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1PTfM1LsvP8W",
        "outputId": "f3e6b071-0fe9-4c10-cbaa-622cd8231afd"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoded: [196, 371, 527, 16, 10015]\n",
            "Decoded: زبان فارسی زیبا است.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "uAAMKovYKq3D"
      },
      "outputs": [],
      "source": [
        "#change input to tokens_id\n",
        "def tokenizer(sentence):\n",
        "    tmp=[]\n",
        "    tmp.append(vocab_to_int[\"<sos>\"])\n",
        "    for word in word_tokenize(sentence):\n",
        "        cleaned_string = pattern.sub(\"\", word)\n",
        "        if cleaned_string not in vocab_to_int:\n",
        "            tmp.append(vocab_to_int[\"<UNK>\"])\n",
        "        else:\n",
        "          tmp.append(vocab_to_int[cleaned_string])\n",
        "    tmp.append(vocab_to_int[\"<eos>\"])\n",
        "    # padded_sequences = tf.keras.preprocessing.sequence.pad_sequences([tmp],maxlen=512 ,padding='post', value=vocab_to_int[\"<PAD>\"])\n",
        "    return tmp\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "_68o2y7HO9pK"
      },
      "outputs": [],
      "source": [
        "def detokenizer(tokens):\n",
        "    tmp=\"\"\n",
        "    for token in tokens:\n",
        "        tmp+=int_to_vocab[token]+\" \"\n",
        "    return tmp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "LqEDJ6MgOVhP"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "jlZAWYfJKq0g"
      },
      "outputs": [],
      "source": [
        "lengths = []\n",
        "\n",
        "for ind in df.index:\n",
        "  wr_tokens = tokenizer(df.at[ind,\"wrong_sentence\"])\n",
        "  lengths.append(len(wr_tokens))\n",
        "  cor_tokens = tokenizer(df.at[ind,\"correct_sentence\"])\n",
        "  lengths.append(len(cor_tokens))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "PqKl2MKGKqxp",
        "outputId": "90eeae74-2ed9-4e2f-84c8-13ef873e8f6b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "\n",
        "plt.hist(lengths, np.linspace(0, 500, 101))\n",
        "plt.ylim(plt.ylim())\n",
        "max_length = max(lengths)\n",
        "plt.plot([max_length, max_length], plt.ylim())\n",
        "plt.title(f'Maximum tokens per example: {max_length}');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "kfCX3Lp9y5uv"
      },
      "outputs": [],
      "source": [
        "wrong_sentence=[]\n",
        "correct_sentence_inputs=[]\n",
        "correct_sentence_labels=[]\n",
        "# MAX_TOKENS=256\n",
        "for ind in df.index:\n",
        "  wrong=tokenizer(df.at[ind,\"wrong_sentence\"])\n",
        "  # wrong=wrong[:, :MAX_TOKENS]    # Trim to MAX_TOKENS.\n",
        "  wrong_sentence.append(tf.keras.preprocessing.sequence.pad_sequences([wrong],maxlen=256 ,padding='post', value=vocab_to_int[\"<PAD>\"],truncating='post')\n",
        ")\n",
        "  correct_inputs=tokenizer(df.at[ind,\"correct_sentence\"])\n",
        "  # correct_sentence = correct_inputs[:, :(MAX_TOKENS+1)]\n",
        "  correct_sentence_inputs_one = correct_inputs[:-1]     #drop <eos>\n",
        "  correct_sentence_labels_one=correct_inputs[1:]        #drop <sos>\n",
        "  correct_sentence_inputs .append(tf.keras.preprocessing.sequence.pad_sequences([correct_sentence_inputs_one],maxlen=256 ,padding='post', value=vocab_to_int[\"<PAD>\"],truncating='post') )\n",
        "  correct_sentence_labels .append(tf.keras.preprocessing.sequence.pad_sequences([correct_sentence_labels_one],maxlen=256 ,padding='post', value=vocab_to_int[\"<PAD>\"],truncating='post') )\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x=tokenizer(df.at[2,\"correct_sentence\"])"
      ],
      "metadata": {
        "id": "Or51PPsadcHR"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "oNGaQgYv0Seb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2a1944a-4c49-4b8b-9c7f-a72f73c6807e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "190\n",
            "189\n",
            "[2, 4, 5, 6, 7, 7, 8, 9, 10, 11, 12, 13, 14, 15, 7, 16, 17, 7, 18, 8, 10, 11, 19, 20, 21, 22, 23, 19, 24, 25, 26, 27, 26, 28, 29, 7, 30, 19, 31, 32, 11, 33, 34, 19, 35, 33, 23, 36, 37, 38, 39, 25, 26, 27, 26, 40, 41, 42, 43, 44, 24, 39, 45, 46, 47, 48, 33, 49, 9, 50, 51, 22, 16, 19, 48, 33, 49, 17, 52, 22, 16, 14, 12, 13, 53, 54, 55, 56, 16, 90, 12, 13, 57, 54, 55, 58, 56, 16, 59, 60, 29, 61, 12, 13, 62, 63, 64, 59, 60, 8, 33, 65, 66, 55, 63, 16, 67, 68, 61, 67, 69, 61, 67, 70, 61, 67, 71, 61, 53, 59, 60, 29, 61, 7, 72, 73, 8, 33, 65, 74, 75, 76, 77, 7, 78, 79, 19, 7, 10, 80, 59, 60, 33, 65, 81, 56, 82, 24, 7, 78, 79, 83, 54, 84, 33, 35, 22, 85, 19, 7, 78, 16, 73, 29, 61, 7, 78, 79, 73, 29, 54, 84, 86, 54, 87, 22, 85, 88, 89]\n"
          ]
        }
      ],
      "source": [
        "print(len(x))\n",
        "x=x[:-1]\n",
        "print(len(x))\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "9DZQPQgH0CUd"
      },
      "outputs": [],
      "source": [
        "df=pd.DataFrame({\n",
        "    \"wrong_sentence\":wrong_sentence,\n",
        "    \"correct_sentence_inputs\":correct_sentence_inputs,\n",
        "    \"correct_sentence_labels\":correct_sentence_labels\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "PeWFcg6M0d6d",
        "outputId": "7ce30322-f9b1-4cda-b674-04855da58dbd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                      wrong_sentence  \\\n",
              "0  [[2, 4, 5, 6, 7, 7, 8, 9, 10, 11, 12, 13, 14, ...   \n",
              "1  [[2, 4, 5, 6, 7, 7, 8, 9, 10, 11, 12, 13, 14, ...   \n",
              "2  [[2, 4, 5, 6, 7, 7, 8, 9, 10, 11, 12, 13, 14, ...   \n",
              "3  [[2, 4, 5, 6, 7, 7, 8, 9, 10, 11, 12, 13, 14, ...   \n",
              "4  [[2, 4, 5, 6, 7, 7, 8, 9, 10, 11, 12, 13, 14, ...   \n",
              "\n",
              "                             correct_sentence_inputs  \\\n",
              "0  [[2, 4, 5, 6, 7, 7, 8, 9, 10, 11, 12, 13, 14, ...   \n",
              "1  [[2, 4, 5, 6, 7, 7, 8, 9, 10, 11, 12, 13, 14, ...   \n",
              "2  [[2, 4, 5, 6, 7, 7, 8, 9, 10, 11, 12, 13, 14, ...   \n",
              "3  [[2, 4, 5, 6, 7, 7, 8, 9, 10, 11, 12, 13, 14, ...   \n",
              "4  [[2, 4, 5, 6, 7, 7, 8, 9, 10, 11, 12, 13, 14, ...   \n",
              "\n",
              "                             correct_sentence_labels  \n",
              "0  [[4, 5, 6, 7, 7, 8, 9, 10, 11, 12, 13, 14, 15,...  \n",
              "1  [[4, 5, 6, 7, 7, 8, 9, 10, 11, 12, 13, 14, 15,...  \n",
              "2  [[4, 5, 6, 7, 7, 8, 9, 10, 11, 12, 13, 14, 15,...  \n",
              "3  [[4, 5, 6, 7, 7, 8, 9, 10, 11, 12, 13, 14, 15,...  \n",
              "4  [[4, 5, 6, 7, 7, 8, 9, 10, 11, 12, 13, 14, 15,...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3667db80-cb9f-4f4d-94a6-4c14b602afb9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>wrong_sentence</th>\n",
              "      <th>correct_sentence_inputs</th>\n",
              "      <th>correct_sentence_labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[[2, 4, 5, 6, 7, 7, 8, 9, 10, 11, 12, 13, 14, ...</td>\n",
              "      <td>[[2, 4, 5, 6, 7, 7, 8, 9, 10, 11, 12, 13, 14, ...</td>\n",
              "      <td>[[4, 5, 6, 7, 7, 8, 9, 10, 11, 12, 13, 14, 15,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[[2, 4, 5, 6, 7, 7, 8, 9, 10, 11, 12, 13, 14, ...</td>\n",
              "      <td>[[2, 4, 5, 6, 7, 7, 8, 9, 10, 11, 12, 13, 14, ...</td>\n",
              "      <td>[[4, 5, 6, 7, 7, 8, 9, 10, 11, 12, 13, 14, 15,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[[2, 4, 5, 6, 7, 7, 8, 9, 10, 11, 12, 13, 14, ...</td>\n",
              "      <td>[[2, 4, 5, 6, 7, 7, 8, 9, 10, 11, 12, 13, 14, ...</td>\n",
              "      <td>[[4, 5, 6, 7, 7, 8, 9, 10, 11, 12, 13, 14, 15,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[[2, 4, 5, 6, 7, 7, 8, 9, 10, 11, 12, 13, 14, ...</td>\n",
              "      <td>[[2, 4, 5, 6, 7, 7, 8, 9, 10, 11, 12, 13, 14, ...</td>\n",
              "      <td>[[4, 5, 6, 7, 7, 8, 9, 10, 11, 12, 13, 14, 15,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[[2, 4, 5, 6, 7, 7, 8, 9, 10, 11, 12, 13, 14, ...</td>\n",
              "      <td>[[2, 4, 5, 6, 7, 7, 8, 9, 10, 11, 12, 13, 14, ...</td>\n",
              "      <td>[[4, 5, 6, 7, 7, 8, 9, 10, 11, 12, 13, 14, 15,...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3667db80-cb9f-4f4d-94a6-4c14b602afb9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3667db80-cb9f-4f4d-94a6-4c14b602afb9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3667db80-cb9f-4f4d-94a6-4c14b602afb9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-0703d414-e6c7-481c-9347-1d05c3779f2a\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0703d414-e6c7-481c-9347-1d05c3779f2a')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-0703d414-e6c7-481c-9347-1d05c3779f2a button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 9205,\n  \"fields\": [\n    {\n      \"column\": \"wrong_sentence\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"correct_sentence_inputs\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"correct_sentence_labels\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "cLFO9YIIUYv6"
      },
      "outputs": [],
      "source": [
        "train,test=train_test_split(df,test_size=0.2,random_state=24)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "GPQwbsXcdAUX"
      },
      "outputs": [],
      "source": [
        "correct_label=tf.convert_to_tensor(train['correct_sentence_labels'].tolist(), dtype=tf.int64)\n",
        "wrong=tf.convert_to_tensor(train['wrong_sentence'].tolist(), dtype=tf.int64)\n",
        "correct_inputs=tf.convert_to_tensor(train['correct_sentence_inputs'].tolist(), dtype=tf.int64)\n",
        "\n",
        "\n",
        "\n",
        "correct_label_test=tf.convert_to_tensor(test['correct_sentence_labels'].tolist(), dtype=tf.int64)\n",
        "wrong_test=tf.convert_to_tensor(test['wrong_sentence'].tolist(), dtype=tf.int64)\n",
        "correct_inputs_test=tf.convert_to_tensor(test['correct_sentence_inputs'].tolist(), dtype=tf.int64)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "2q-yTYk5Fr1j"
      },
      "outputs": [],
      "source": [
        "correct_label=tf.squeeze(correct_label, axis=1)\n",
        "wrong=tf.squeeze(wrong, axis=1)\n",
        "correct_inputs=tf.squeeze(correct_inputs, axis=1)\n",
        "\n",
        "correct_label_test=tf.squeeze(correct_label_test, axis=1)\n",
        "wrong_test=tf.squeeze(wrong_test, axis=1)\n",
        "correct_inputs_test=tf.squeeze(correct_inputs_test, axis=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "kiW7txpj4Zm8"
      },
      "outputs": [],
      "source": [
        "\n",
        "tensor_dict = (\n",
        "     wrong,\n",
        "     correct_inputs)\n",
        "tensor_dict_test = (\n",
        "     wrong_test,\n",
        "     correct_inputs_test\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "K2LpTcyT5Yp4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "ZKdJwU6BRKfU"
      },
      "outputs": [],
      "source": [
        "dataset_train = tf.data.Dataset.from_tensor_slices((tensor_dict,correct_label))\n",
        "dataset_test = tf.data.Dataset.from_tensor_slices((tensor_dict_test,correct_label_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "KvRg1Jp0RYRh"
      },
      "outputs": [],
      "source": [
        "# dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aat0GsFGSm6K",
        "outputId": "ac439c4d-25a2-4005-f30b-455a2336173f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[   2  320   77  531 1475 5373 5374 5375 5376 5377 5378  226   77 2153\n",
            "  226  404 5379 5380 5381  119 2120   57 4165  119 2156 5367 5382  119\n",
            " 2120 5367  177  256  119   57 2120  231 5383  177 1230   33  558 5384\n",
            " 1551  119  566  183   53 2124  131 5383   33 5367   22  584   89    1\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0], shape=(256,), dtype=int64)\n",
            "tf.Tensor(\n",
            "[   2  320   77  531 1475 5373 5374 5375 5376 5377 5378  226   77 2153\n",
            "  226  404 5379 5380 5381  119 2120   57 4165  119 2156 5367 5382  119\n",
            " 2120 5367  177  256  119   89   57 2120  231 5383  177 1230   33  558\n",
            " 5384 1551  119  566  183   53 2124  131 5383   33 5367   22  584   89\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0], shape=(256,), dtype=int64)\n",
            "tf.Tensor(\n",
            "[ 320   77  531 1475 5373 5374 5375 5376 5377 5378  226   77 2153  226\n",
            "  404 5379 5380 5381  119 2120   57 4165  119 2156 5367 5382  119 2120\n",
            " 5367  177  256  119   89   57 2120  231 5383  177 1230   33  558 5384\n",
            " 1551  119  566  183   53 2124  131 5383   33 5367   22  584   89    1\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0], shape=(256,), dtype=int64)\n"
          ]
        }
      ],
      "source": [
        "for (wrong,correct_inputs) ,label in dataset_train.take(1):\n",
        "    print(wrong)\n",
        "    print(correct_inputs)\n",
        "    print(label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "pf7mMh-kRnvt"
      },
      "outputs": [],
      "source": [
        "\n",
        "MAX_TOKENS=256\n",
        "def prepare_batch(wrong_sentence,correct_sentence):\n",
        "    wrong_sentence = tokenizer(wrong_sentence)      # Output is ragged.\n",
        "    wrong_sentence = wrong_sentence[:, :MAX_TOKENS]    # Trim to MAX_TOKENS.\n",
        "    print(wrong_sentence)\n",
        "    wrong_sentence = wrong_sentence.to_tensor()  # Convert to 0-padded dense Tensor\n",
        "\n",
        "    correct_sentence = tokenizer(correct_sentence)\n",
        "    correct_sentence = correct_sentence[:, :(MAX_TOKENS+1)]\n",
        "    correct_sentence_inputs = correct_sentence[:, :-1].to_tensor()  # Drop the [END] tokens\n",
        "    correct_sentence_labels = correct_sentence[:, 1:].to_tensor()   # Drop the [START] tokens\n",
        "\n",
        "    return (wrong_sentence, correct_sentence_inputs), correct_sentence_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "Z1FQQqHuKqsS"
      },
      "outputs": [],
      "source": [
        "BUFFER_SIZE = 20000\n",
        "BATCH_SIZE = 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "F3BAyAe0Q3zq"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "epWINy_lKqpV"
      },
      "outputs": [],
      "source": [
        "def make_batches(ds):\n",
        "  return (\n",
        "      ds\n",
        "      .shuffle(BUFFER_SIZE)\n",
        "      .batch(BATCH_SIZE))\n",
        "      # .map(prepare_batch, tf.data.AUTOTUNE)\n",
        "      # .prefetch(buffer_size=tf.data.AUTOTUNE))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "Z-6k9N5fQ0qS"
      },
      "outputs": [],
      "source": [
        "# Create training and validation set batches.\n",
        "train_batches = make_batches(dataset_train)\n",
        "val_batches = make_batches(dataset_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "PB3CRNX-8Wzg"
      },
      "outputs": [],
      "source": [
        "# for x,c in train_batches.take(1):\n",
        "#   print(x)\n",
        "#   print(c)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "Jgt0XnfxCm-L"
      },
      "outputs": [],
      "source": [
        "def positional_encoding(length, depth):\n",
        "  depth = depth/2\n",
        "\n",
        "  positions = np.arange(length)[:, np.newaxis]     # (seq, 1)\n",
        "  depths = np.arange(depth)[np.newaxis, :]/depth   # (1, depth)\n",
        "\n",
        "  angle_rates = 1 / (10000**depths)         # (1, depth)\n",
        "  angle_rads = positions * angle_rates      # (pos, depth)\n",
        "\n",
        "  pos_encoding = np.concatenate(\n",
        "      [np.sin(angle_rads), np.cos(angle_rads)],\n",
        "      axis=-1)\n",
        "\n",
        "  return tf.cast(pos_encoding, dtype=tf.float32)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "IO5qLxJlCvpT"
      },
      "outputs": [],
      "source": [
        "class PositionalEmbedding(tf.keras.layers.Layer):\n",
        "  def __init__(self, vocab_size, d_model):\n",
        "    super().__init__()\n",
        "    self.d_model = d_model\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, d_model, mask_zero=True)\n",
        "    self.pos_encoding = positional_encoding(length=2048, depth=d_model)\n",
        "\n",
        "  def compute_mask(self, *args, **kwargs):\n",
        "    return self.embedding.compute_mask(*args, **kwargs)\n",
        "\n",
        "  def call(self, x):\n",
        "    length = tf.shape(x)[1]\n",
        "    x = self.embedding(x)\n",
        "    # This factor sets the relative scale of the embedding and positonal_encoding.\n",
        "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "    x = x + self.pos_encoding[tf.newaxis, :length, :]\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "IdGErdpt-tZz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ab33829-6233-4da4-d090-5a1fea2e85ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 256)\n",
            "(64, 256)\n",
            "(64, 256)\n",
            "tf.Tensor([ 64 256], shape=(2,), dtype=int32)\n"
          ]
        }
      ],
      "source": [
        "for (wrong_sentence,correct_sentence), correct_sentence_labels in train_batches.take(1):\n",
        "  break\n",
        "print(wrong_sentence.shape)\n",
        "print(correct_sentence.shape)\n",
        "print(correct_sentence_labels.shape)\n",
        "print(tf.shape(wrong_sentence))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "TBkFMfw4-9VE"
      },
      "outputs": [],
      "source": [
        "# print(wrong_sentence[0][:10])\n",
        "# print(correct_sentence_labels[0][:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "5syWSMLiC4Ls",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79dfd391-57b1-43be-9bd9-31370f91fd67"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 256, 512)\n"
          ]
        }
      ],
      "source": [
        "embed_wrong = PositionalEmbedding(vocab_size=len(vocab_to_int), d_model=512)\n",
        "embed_correct = PositionalEmbedding(vocab_size=len(vocab_to_int), d_model=512)\n",
        "\n",
        "wrong_emb = embed_wrong(wrong_sentence)\n",
        "correct_emb = embed_correct(correct_sentence)\n",
        "print(wrong_emb.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "nNmFpNi_-qnI"
      },
      "outputs": [],
      "source": [
        "# correct_emb._keras_mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "4G12SepD7PXL"
      },
      "outputs": [],
      "source": [
        "class BaseAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, **kwargs):\n",
        "    super().__init__()\n",
        "    self.mha = tf.keras.layers.MultiHeadAttention(**kwargs)\n",
        "    self.layernorm = tf.keras.layers.LayerNormalization()\n",
        "    self.add = tf.keras.layers.Add()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "p-1d0LMf8eTA"
      },
      "outputs": [],
      "source": [
        "class CrossAttention(BaseAttention):\n",
        "  def call(self, x, context):\n",
        "    attn_output, attn_scores = self.mha(\n",
        "        query=x,\n",
        "        key=context,\n",
        "        value=context,\n",
        "        return_attention_scores=True)\n",
        "\n",
        "    # Cache the attention scores for plotting later.\n",
        "    self.last_attn_scores = attn_scores\n",
        "\n",
        "    x = self.add([x, attn_output])\n",
        "    x = self.layernorm(x)\n",
        "\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "lkGW93l9G6nW"
      },
      "outputs": [],
      "source": [
        "# sample_ca = CrossAttention(num_heads=2, key_dim=512)\n",
        "\n",
        "# print(wrong_emb.shape)\n",
        "# print(correct_emb.shape)\n",
        "# print(sample_ca(correct_emb, wrong_emb).shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "4xSQBoMG8fR2"
      },
      "outputs": [],
      "source": [
        "class GlobalSelfAttention(BaseAttention):\n",
        "  def call(self, x):\n",
        "    attn_output = self.mha(\n",
        "        query=x,\n",
        "        value=x,\n",
        "        key=x)\n",
        "    x = self.add([x, attn_output])\n",
        "    x = self.layernorm(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "0JcerZizH2ma"
      },
      "outputs": [],
      "source": [
        "# sample_gsa = GlobalSelfAttention(num_heads=2, key_dim=512)\n",
        "\n",
        "# print(wrong_emb.shape)\n",
        "# print(sample_gsa(wrong_emb).shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "2TNYIVqR9yss"
      },
      "outputs": [],
      "source": [
        "class CausalSelfAttention(BaseAttention):\n",
        "  def call(self, x):\n",
        "    attn_output = self.mha(\n",
        "        query=x,\n",
        "        value=x,\n",
        "        key=x,\n",
        "        use_causal_mask = True)\n",
        "    x = self.add([x, attn_output])\n",
        "    x = self.layernorm(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "TWVXSoRGIe2T"
      },
      "outputs": [],
      "source": [
        "# sample_csa = CausalSelfAttention(num_heads=2, key_dim=512)\n",
        "\n",
        "# print(correct_emb.shape)\n",
        "# print(sample_csa(correct_emb).shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "gzeh5bqR_y8F"
      },
      "outputs": [],
      "source": [
        "class FeedForward(tf.keras.layers.Layer):\n",
        "  def __init__(self, d_model, dff, dropout_rate=0.1):\n",
        "    super().__init__()\n",
        "    self.seq = tf.keras.Sequential([\n",
        "      tf.keras.layers.Dense(dff, activation='relu'),\n",
        "      tf.keras.layers.Dense(d_model),\n",
        "      tf.keras.layers.Dropout(dropout_rate)\n",
        "    ])\n",
        "    self.add = tf.keras.layers.Add()\n",
        "    self.layer_norm = tf.keras.layers.LayerNormalization()\n",
        "\n",
        "  def call(self, x):\n",
        "    x = self.add([x, self.seq(x)])\n",
        "    x = self.layer_norm(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "-5u2_8KC_7js"
      },
      "outputs": [],
      "source": [
        "class EncoderLayer(tf.keras.layers.Layer):\n",
        "  def __init__(self,*, d_model, num_heads, dff, dropout_rate=0.1):\n",
        "    super().__init__()\n",
        "\n",
        "    self.self_attention = GlobalSelfAttention(\n",
        "        num_heads=num_heads,\n",
        "        key_dim=d_model,\n",
        "        dropout=dropout_rate)\n",
        "\n",
        "    self.ffn = FeedForward(d_model, dff)\n",
        "\n",
        "  def call(self, x):\n",
        "    x = self.self_attention(x)\n",
        "    x = self.ffn(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "7Gc0F6_0I0VB"
      },
      "outputs": [],
      "source": [
        "# sample_encoder_layer = EncoderLayer(d_model=512, num_heads=8, dff=2048)\n",
        "\n",
        "# print(wrong_emb.shape)\n",
        "# print(sample_encoder_layer(wrong_emb).shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "O-afzG-zAGFH"
      },
      "outputs": [],
      "source": [
        "class Encoder(tf.keras.layers.Layer):\n",
        "  def __init__(self, *, num_layers, d_model, num_heads,\n",
        "               dff, vocab_size, dropout_rate=0.1):\n",
        "    super().__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.num_layers = num_layers\n",
        "\n",
        "    self.pos_embedding = PositionalEmbedding(\n",
        "        vocab_size=vocab_size, d_model=d_model)\n",
        "\n",
        "    self.enc_layers = [\n",
        "        EncoderLayer(d_model=d_model,\n",
        "                     num_heads=num_heads,\n",
        "                     dff=dff,\n",
        "                     dropout_rate=dropout_rate)\n",
        "        for _ in range(num_layers)]\n",
        "    self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
        "\n",
        "  def call(self, x):\n",
        "    # `x` is token-IDs shape: (batch, seq_len)\n",
        "    x = self.pos_embedding(x)  # Shape `(batch_size, seq_len, d_model)`.\n",
        "\n",
        "    # Add dropout.\n",
        "    x = self.dropout(x)\n",
        "\n",
        "    for i in range(self.num_layers):\n",
        "      x = self.enc_layers[i](x)\n",
        "\n",
        "    return x  # Shape `(batch_size, seq_len, d_model)`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "gU13yJSYCER2"
      },
      "outputs": [],
      "source": [
        "# sample_encoder = Encoder(num_layers=4,\n",
        "#                          d_model=512,\n",
        "#                          num_heads=8,\n",
        "#                          dff=2048,\n",
        "#                          vocab_size=len(vocab_to_int))\n",
        "\n",
        "# sample_encoder_output = sample_encoder(wrong_sentence, training=False)\n",
        "\n",
        "# # Print the shape.\n",
        "# print(wrong_sentence.shape)\n",
        "# print(sample_encoder_output.shape)  # Shape `(batch_size, input_seq_len, d_model)`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "f58eAaa0Atem"
      },
      "outputs": [],
      "source": [
        "class DecoderLayer(tf.keras.layers.Layer):\n",
        "  def __init__(self,\n",
        "               *,\n",
        "               d_model,\n",
        "               num_heads,\n",
        "               dff,\n",
        "               dropout_rate=0.1):\n",
        "    super(DecoderLayer, self).__init__()\n",
        "\n",
        "    self.causal_self_attention = CausalSelfAttention(\n",
        "        num_heads=num_heads,\n",
        "        key_dim=d_model,\n",
        "        dropout=dropout_rate)\n",
        "\n",
        "    self.cross_attention = CrossAttention(\n",
        "        num_heads=num_heads,\n",
        "        key_dim=d_model,\n",
        "        dropout=dropout_rate)\n",
        "\n",
        "    self.ffn = FeedForward(d_model, dff)\n",
        "\n",
        "  def call(self, x, context):\n",
        "    x = self.causal_self_attention(x=x)\n",
        "    x = self.cross_attention(x=x, context=context)\n",
        "\n",
        "    # Cache the last attention scores for plotting later\n",
        "    self.last_attn_scores = self.cross_attention.last_attn_scores\n",
        "\n",
        "    x = self.ffn(x)  # Shape `(batch_size, seq_len, d_model)`.\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "DfVYusfIJp5K"
      },
      "outputs": [],
      "source": [
        "# sample_decoder_layer = DecoderLayer(d_model=512, num_heads=8, dff=2048)\n",
        "\n",
        "# sample_decoder_layer_output = sample_decoder_layer(\n",
        "#     x=correct_emb, context=wrong_emb)\n",
        "\n",
        "# print(correct_emb.shape)\n",
        "# print(wrong_emb.shape)\n",
        "# print(sample_decoder_layer_output.shape)  # `(batch_size, seq_len, d_model)`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "iRmRXWvIAz_j"
      },
      "outputs": [],
      "source": [
        "class Decoder(tf.keras.layers.Layer):\n",
        "  def __init__(self, *, num_layers, d_model, num_heads, dff, vocab_size,\n",
        "               dropout_rate=0.1):\n",
        "    super(Decoder, self).__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.num_layers = num_layers\n",
        "\n",
        "    self.pos_embedding = PositionalEmbedding(vocab_size=vocab_size,\n",
        "                                             d_model=d_model)\n",
        "    self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
        "    self.dec_layers = [\n",
        "        DecoderLayer(d_model=d_model, num_heads=num_heads,\n",
        "                     dff=dff, dropout_rate=dropout_rate)\n",
        "        for _ in range(num_layers)]\n",
        "\n",
        "    self.last_attn_scores = None\n",
        "\n",
        "  def call(self, x, context):\n",
        "    # `x` is token-IDs shape (batch, target_seq_len)\n",
        "    x = self.pos_embedding(x)  # (batch_size, target_seq_len, d_model)\n",
        "\n",
        "    x = self.dropout(x)\n",
        "\n",
        "    for i in range(self.num_layers):\n",
        "      x  = self.dec_layers[i](x, context)\n",
        "\n",
        "    self.last_attn_scores = self.dec_layers[-1].last_attn_scores\n",
        "\n",
        "    # The shape of x is (batch_size, target_seq_len, d_model).\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "U7a3tO6LJ_jp"
      },
      "outputs": [],
      "source": [
        "# # Instantiate the decoder.\n",
        "# sample_decoder = Decoder(num_layers=4,\n",
        "#                          d_model=512,\n",
        "#                          num_heads=8,\n",
        "#                          dff=2048,\n",
        "#                          vocab_size=len(vocab_to_int))\n",
        "\n",
        "# output = sample_decoder(\n",
        "#     x=correct_sentence,\n",
        "#     context=wrong_emb)\n",
        "\n",
        "# # Print the shapes.\n",
        "# print(correct_sentence.shape)\n",
        "# print(wrong_emb.shape)\n",
        "# print(output.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "sZ9DEd9gKpZ5"
      },
      "outputs": [],
      "source": [
        "# sample_decoder.last_attn_scores.shape  # (batch, heads, target_seq, input_seq)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "fWpVS0R1A2Q-"
      },
      "outputs": [],
      "source": [
        "class Transformer(tf.keras.Model):\n",
        "  def __init__(self, *, num_layers, d_model, num_heads, dff,\n",
        "               input_vocab_size, target_vocab_size, dropout_rate=0.1):\n",
        "    super().__init__()\n",
        "    self.encoder = Encoder(num_layers=num_layers, d_model=d_model,\n",
        "                           num_heads=num_heads, dff=dff,\n",
        "                           vocab_size=input_vocab_size,\n",
        "                           dropout_rate=dropout_rate)\n",
        "\n",
        "    self.decoder = Decoder(num_layers=num_layers, d_model=d_model,\n",
        "                           num_heads=num_heads, dff=dff,\n",
        "                           vocab_size=target_vocab_size,\n",
        "                           dropout_rate=dropout_rate)\n",
        "\n",
        "    self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
        "\n",
        "  def call(self, inputs):\n",
        "    # To use a Keras model with `.fit` you must pass all your inputs in the\n",
        "    # first argument.\n",
        "    context, x  = inputs\n",
        "\n",
        "    context = self.encoder(context)  # (batch_size, context_len, d_model)\n",
        "\n",
        "    x = self.decoder(x, context)  # (batch_size, target_len, d_model)\n",
        "\n",
        "    # Final linear layer output.\n",
        "    logits = self.final_layer(x)  # (batch_size, target_len, target_vocab_size)\n",
        "\n",
        "    try:\n",
        "      # Drop the keras mask, so it doesn't scale the losses/metrics.\n",
        "      # b/250038731\n",
        "      del logits._keras_mask\n",
        "    except AttributeError:\n",
        "      pass\n",
        "\n",
        "    # Return the final output and the attention weights.\n",
        "    return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "7Xk_VsjcBm4Z"
      },
      "outputs": [],
      "source": [
        "num_layers = 4\n",
        "d_model = 128\n",
        "dff = 512\n",
        "num_heads = 8\n",
        "dropout_rate = 0.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "8cu56QXiQFvr"
      },
      "outputs": [],
      "source": [
        "transformer = Transformer(\n",
        "    num_layers=num_layers,\n",
        "    d_model=d_model,\n",
        "    num_heads=num_heads,\n",
        "    dff=dff,\n",
        "    input_vocab_size=len(vocab_to_int),\n",
        "    target_vocab_size=len(vocab_to_int),\n",
        "    dropout_rate=dropout_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "2_1F1XfKK4Jb"
      },
      "outputs": [],
      "source": [
        "# output = transformer((wrong_sentence, correct_sentence))\n",
        "\n",
        "# print(correct_sentence.shape)\n",
        "# print(wrong_sentence.shape)\n",
        "# print(output.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "g33heYNuMrnh"
      },
      "outputs": [],
      "source": [
        "# attn_scores = transformer.decoder.dec_layers[-1].last_attn_scores\n",
        "# print(attn_scores.shape)  # (batch, heads, target_seq, input_seq)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "UsrJTkNZMuyv"
      },
      "outputs": [],
      "source": [
        "# transformer.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "PrrV0G4qB2rh"
      },
      "outputs": [],
      "source": [
        "transformer = Transformer(\n",
        "    num_layers=num_layers,\n",
        "    d_model=d_model,\n",
        "    num_heads=num_heads,\n",
        "    dff=dff,\n",
        "    input_vocab_size=len(vocab_to_int),\n",
        "    target_vocab_size=len(vocab_to_int),\n",
        "    dropout_rate=dropout_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "yCIAmc3XB60w"
      },
      "outputs": [],
      "source": [
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "  def __init__(self, d_model, warmup_steps=4000):\n",
        "    super().__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
        "\n",
        "    self.warmup_steps = warmup_steps\n",
        "\n",
        "  def __call__(self, step):\n",
        "    step = tf.cast(step, dtype=tf.float32)\n",
        "    arg1 = tf.math.rsqrt(step)\n",
        "    arg2 = step * (self.warmup_steps ** -1.5)\n",
        "\n",
        "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "A9xusyZUCpXx"
      },
      "outputs": [],
      "source": [
        "learning_rate = CustomSchedule(d_model)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98,\n",
        "                                     epsilon=1e-9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "id": "3O7UI3zlCvDK",
        "outputId": "1ef26e1f-8ede-45e4-ed7c-03e8e4c4f8df"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'Train Step')"
            ]
          },
          "metadata": {},
          "execution_count": 68
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "plt.plot(learning_rate(tf.range(40000, dtype=tf.float32)))\n",
        "plt.ylabel('Learning Rate')\n",
        "plt.xlabel('Train Step')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "qW4E5DqaC9SK"
      },
      "outputs": [],
      "source": [
        "def masked_loss(label, pred):\n",
        "  mask = label != 0\n",
        "  loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')\n",
        "  loss = loss_object(label, pred)\n",
        "\n",
        "  mask = tf.cast(mask, dtype=loss.dtype)\n",
        "  loss *= mask\n",
        "\n",
        "  loss = tf.reduce_sum(loss)/tf.reduce_sum(mask)\n",
        "  return loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "095iqf2KC-GP"
      },
      "outputs": [],
      "source": [
        "def masked_accuracy(label, pred):\n",
        "  pred = tf.argmax(pred, axis=2)\n",
        "  label = tf.cast(label, pred.dtype)\n",
        "  match = label == pred\n",
        "\n",
        "  mask = label != 0\n",
        "\n",
        "  match = match & mask\n",
        "\n",
        "  match = tf.cast(match, dtype=tf.float32)\n",
        "  mask = tf.cast(mask, dtype=tf.float32)\n",
        "  return tf.reduce_sum(match)/tf.reduce_sum(mask)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "4zLVzNcpDIL4"
      },
      "outputs": [],
      "source": [
        "transformer.compile(\n",
        "    loss=masked_loss,\n",
        "    optimizer=optimizer,\n",
        "    metrics=[masked_accuracy])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z9VSkwuUDM4j",
        "outputId": "9b02430a-afb7-4229-de06-31210f075f84"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'query' (of type EinsumDense) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'key' (of type EinsumDense) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'value' (of type EinsumDense) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'global_self_attention_4' (of type GlobalSelfAttention) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'sequential_8' (of type Sequential) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'feed_forward_8' (of type FeedForward) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'encoder_layer_4' (of type EncoderLayer) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'global_self_attention_5' (of type GlobalSelfAttention) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'sequential_9' (of type Sequential) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'feed_forward_9' (of type FeedForward) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'encoder_layer_5' (of type EncoderLayer) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'global_self_attention_6' (of type GlobalSelfAttention) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'sequential_10' (of type Sequential) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'feed_forward_10' (of type FeedForward) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'encoder_layer_6' (of type EncoderLayer) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'global_self_attention_7' (of type GlobalSelfAttention) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'sequential_11' (of type Sequential) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'feed_forward_11' (of type FeedForward) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'encoder_layer_7' (of type EncoderLayer) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'causal_self_attention_4' (of type CausalSelfAttention) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'cross_attention_4' (of type CrossAttention) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'sequential_12' (of type Sequential) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'feed_forward_12' (of type FeedForward) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'decoder_layer_4' (of type DecoderLayer) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'causal_self_attention_5' (of type CausalSelfAttention) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'cross_attention_5' (of type CrossAttention) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'sequential_13' (of type Sequential) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'feed_forward_13' (of type FeedForward) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'decoder_layer_5' (of type DecoderLayer) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'causal_self_attention_6' (of type CausalSelfAttention) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'cross_attention_6' (of type CrossAttention) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'sequential_14' (of type Sequential) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'feed_forward_14' (of type FeedForward) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'decoder_layer_6' (of type DecoderLayer) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'causal_self_attention_7' (of type CausalSelfAttention) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'cross_attention_7' (of type CrossAttention) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'sequential_15' (of type Sequential) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'feed_forward_15' (of type FeedForward) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'decoder_layer_7' (of type DecoderLayer) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m160s\u001b[0m 887ms/step - loss: 9.1202 - masked_accuracy: 0.0107 - val_loss: 8.7358 - val_masked_accuracy: 0.0445\n",
            "Epoch 2/30\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 646ms/step - loss: 8.5376 - masked_accuracy: 0.0524 - val_loss: 7.8297 - val_masked_accuracy: 0.0797\n",
            "Epoch 3/30\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 610ms/step - loss: 7.5711 - masked_accuracy: 0.0831 - val_loss: 6.8712 - val_masked_accuracy: 0.1262\n",
            "Epoch 4/30\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 610ms/step - loss: 6.6689 - masked_accuracy: 0.1410 - val_loss: 6.1632 - val_masked_accuracy: 0.1723\n",
            "Epoch 5/30\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 610ms/step - loss: 5.9369 - masked_accuracy: 0.1917 - val_loss: 5.2988 - val_masked_accuracy: 0.2437\n",
            "Epoch 6/30\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 613ms/step - loss: 5.0049 - masked_accuracy: 0.2775 - val_loss: 4.3198 - val_masked_accuracy: 0.3636\n",
            "Epoch 7/30\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 651ms/step - loss: 3.9707 - masked_accuracy: 0.4052 - val_loss: 3.4331 - val_masked_accuracy: 0.5186\n",
            "Epoch 8/30\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 655ms/step - loss: 3.0374 - masked_accuracy: 0.5440 - val_loss: 2.7998 - val_masked_accuracy: 0.5727\n",
            "Epoch 9/30\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 616ms/step - loss: 2.2768 - masked_accuracy: 0.6596 - val_loss: 1.9826 - val_masked_accuracy: 0.7169\n",
            "Epoch 10/30\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 611ms/step - loss: 1.5927 - masked_accuracy: 0.7657 - val_loss: 1.5762 - val_masked_accuracy: 0.7710\n",
            "Epoch 11/30\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 610ms/step - loss: 1.1572 - masked_accuracy: 0.8296 - val_loss: 1.1625 - val_masked_accuracy: 0.8462\n",
            "Epoch 12/30\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 615ms/step - loss: 0.7898 - masked_accuracy: 0.8865 - val_loss: 0.9518 - val_masked_accuracy: 0.8725\n",
            "Epoch 13/30\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 612ms/step - loss: 0.5903 - masked_accuracy: 0.9140 - val_loss: 0.8784 - val_masked_accuracy: 0.8809\n",
            "Epoch 14/30\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 652ms/step - loss: 0.4656 - masked_accuracy: 0.9303 - val_loss: 0.7541 - val_masked_accuracy: 0.8994\n",
            "Epoch 15/30\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 655ms/step - loss: 0.3537 - masked_accuracy: 0.9457 - val_loss: 0.7643 - val_masked_accuracy: 0.8906\n",
            "Epoch 16/30\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 619ms/step - loss: 0.2906 - masked_accuracy: 0.9534 - val_loss: 0.7207 - val_masked_accuracy: 0.9019\n",
            "Epoch 17/30\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 653ms/step - loss: 0.2464 - masked_accuracy: 0.9580 - val_loss: 0.6078 - val_masked_accuracy: 0.9234\n",
            "Epoch 18/30\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 653ms/step - loss: 0.1893 - masked_accuracy: 0.9645 - val_loss: 0.6155 - val_masked_accuracy: 0.9206\n",
            "Epoch 19/30\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 618ms/step - loss: 0.1723 - masked_accuracy: 0.9659 - val_loss: 0.5705 - val_masked_accuracy: 0.9257\n",
            "Epoch 20/30\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 611ms/step - loss: 0.1584 - masked_accuracy: 0.9671 - val_loss: 0.5822 - val_masked_accuracy: 0.9271\n",
            "Epoch 21/30\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 609ms/step - loss: 0.1509 - masked_accuracy: 0.9676 - val_loss: 0.5807 - val_masked_accuracy: 0.9267\n",
            "Epoch 22/30\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 616ms/step - loss: 0.1450 - masked_accuracy: 0.9672 - val_loss: 0.5916 - val_masked_accuracy: 0.9213\n",
            "Epoch 23/30\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 613ms/step - loss: 0.1353 - masked_accuracy: 0.9686 - val_loss: 0.5715 - val_masked_accuracy: 0.9297\n",
            "Epoch 24/30\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 617ms/step - loss: 0.1282 - masked_accuracy: 0.9690 - val_loss: 0.5868 - val_masked_accuracy: 0.9270\n",
            "Epoch 25/30\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 646ms/step - loss: 0.1287 - masked_accuracy: 0.9685 - val_loss: 0.5957 - val_masked_accuracy: 0.9263\n",
            "Epoch 26/30\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 617ms/step - loss: 0.1335 - masked_accuracy: 0.9673 - val_loss: 0.5867 - val_masked_accuracy: 0.9303\n",
            "Epoch 27/30\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 619ms/step - loss: 0.1191 - masked_accuracy: 0.9699 - val_loss: 0.6107 - val_masked_accuracy: 0.9250\n",
            "Epoch 28/30\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 612ms/step - loss: 0.1214 - masked_accuracy: 0.9695 - val_loss: 0.6537 - val_masked_accuracy: 0.9159\n",
            "Epoch 29/30\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 609ms/step - loss: 0.1374 - masked_accuracy: 0.9661 - val_loss: 0.6191 - val_masked_accuracy: 0.9253\n",
            "Epoch 30/30\n",
            "\u001b[1m116/116\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 650ms/step - loss: 0.1214 - masked_accuracy: 0.9691 - val_loss: 0.6071 - val_masked_accuracy: 0.9292\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7ee687659000>"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ],
      "source": [
        "transformer.fit(train_batches,\n",
        "                epochs=30,\n",
        "                validation_data=val_batches)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "Gb5xNRGnDOMI"
      },
      "outputs": [],
      "source": [
        "class Spell_correction(tf.Module):\n",
        "  def __init__(self, tokenizers, transformer):\n",
        "    self.tokenizers = tokenizers\n",
        "    self.transformer = transformer\n",
        "\n",
        "  def __call__(self, sentence, max_length=MAX_TOKENS):\n",
        "    # print(sentence.shape)\n",
        "    # The input sentence is Portuguese, hence adding the `[START]` and `[END]` tokens.\n",
        "    # assert isinstance(sentence, tf.Tensor)\n",
        "    # if len(sentence.shape) == 0:\n",
        "    #   sentence = sentence[tf.newaxis]\n",
        "    x=self.tokenizers(sentence)\n",
        "    x_1=tf.keras.preprocessing.sequence.pad_sequences([x],maxlen=256 ,padding='post', value=vocab_to_int[\"<PAD>\"],truncating='post')\n",
        "\n",
        "    sentence =tf.convert_to_tensor( x_1,dtype=tf.int64)\n",
        "    encoder_input = sentence\n",
        "\n",
        "    # As the output language is English, initialize the output with the\n",
        "    # English `[START]` token.\n",
        "    # start_end = self.tokenizers.en.tokenize([''])[0]\n",
        "    # start = start_end[0][tf.newaxis]\n",
        "    # end = start_end[1][tf.newaxis]\n",
        "\n",
        "    list_temp=[]\n",
        "    list_temp.append(vocab_to_int['<sos>'])\n",
        "    start=tf.constant(list_temp,dtype=tf.int64)\n",
        "    list_temp=[]\n",
        "    list_temp.append(vocab_to_int['<eos>'])\n",
        "    end=tf.constant(list_temp,dtype=tf.int64)\n",
        "    # `tf.TensorArray` is required here (instead of a Python list), so that the\n",
        "    # dynamic-loop can be traced by `tf.function`.\n",
        "    output_array = tf.TensorArray(dtype=tf.int64, size=0, dynamic_size=True)\n",
        "    output_array = output_array.write(0, start)\n",
        "    # print(output_array.shape)\n",
        "    for i in tf.range(max_length):\n",
        "\n",
        "      output = tf.transpose(output_array.stack())\n",
        "      predictions = self.transformer([encoder_input, output], training=False)\n",
        "\n",
        "      # Select the last token from the `seq_len` dimension.\n",
        "      predictions = predictions[:, -1:, :]  # Shape `(batch_size, 1, vocab_size)`.\n",
        "\n",
        "      predicted_id = tf.argmax(predictions, axis=-1)\n",
        "\n",
        "      # Concatenate the `predicted_id` to the output which is given to the\n",
        "      # decoder as its input.\n",
        "      output_array = output_array.write(i+1, predicted_id[0])\n",
        "\n",
        "      if predicted_id == end:\n",
        "        break\n",
        "\n",
        "    output = tf.transpose(output_array.stack())\n",
        "    # The output shape is `(1, tokens)`.\n",
        "    # text = tokenizers.en.detokenize(output)[0]  # Shape: `()`.\n",
        "\n",
        "    # tokens = tokenizers.en.lookup(output)[0]\n",
        "    text=detokenizer(output.numpy().tolist()[0])\n",
        "    # Return the tokens\n",
        "    tokens=[]\n",
        "    for num in output.numpy().tolist()[0]:\n",
        "      tokens.append(int_to_vocab[num])\n",
        "    # `tf.function` prevents us from using the attention_weights that were\n",
        "    # calculated on the last iteration of the loop.\n",
        "    # So, recalculate them outside the loop.\n",
        "    self.transformer([encoder_input, output[:,:-1]], training=False)\n",
        "    attention_weights = self.transformer.decoder.last_attn_scores\n",
        "\n",
        "    return text,tokens, attention_weights"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def print_correction(sentence, tokens, ground_truth):\n",
        "  print(f'{\"Input:\":15s}: {sentence}')\n",
        "  print(f'{\"Prediction\":15s}: {tokens}')\n",
        "  print(f'{\"Ground truth\":15s}: {ground_truth}')"
      ],
      "metadata": {
        "id": "SgK2-hKmskuI"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spell_corrector = Spell_correction(tokenizer, transformer)"
      ],
      "metadata": {
        "id": "ScPwxwE0Q4Yq"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input= \"مدرس ها شرو وشود و زیادی بچها در مدرسه سپت نام کرنند .\"\n",
        "ground_truth=\"مدرس ها شرو وشود و زیادی بچه ها در مدرسه سپت نام کرنند .\"\n",
        "\n",
        "\n",
        "\n",
        "translated_text, translated_tokens, attention_weights = spell_corrector(\n",
        "    input)\n",
        "print_correction(input, translated_text, ground_truth)"
      ],
      "metadata": {
        "id": "WH5MtY9LPtiS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9259f88a-12a9-4949-c5d8-49e3039e029f"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/ops/nn.py:545: UserWarning: You are using a softmax over axis 3 of a tensor of shape (1, 8, 1, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input:         : مدرس ها شرو وشود و زیادی بچها در مدرسه سپت نام کرنند .\n",
            "Prediction     : <sos> مدرس ها شرو وشود و زیادی بچها در مدرسه سپت نام کرنند . <eos> \n",
            "Ground truth   : مدرس ها شرو وشود و زیادی بچه ها در مدرسه سپت نام کرنند .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.config.run_functions_eagerly(True)"
      ],
      "metadata": {
        "id": "6NWlVkz9ZIp_"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ExportSpellCorrector(tf.Module):\n",
        "  def __init__(self, spell_corrector):\n",
        "    self.spell_corrector = spell_corrector\n",
        "\n",
        "  @tf.function\n",
        "  def __call__(self, sentence):\n",
        "    (result,\n",
        "     tokens,\n",
        "     attention_weights) = self.spell_corrector(sentence, max_length=MAX_TOKENS)\n",
        "\n",
        "    return result"
      ],
      "metadata": {
        "id": "51xovQiR_OG7"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spell_corrector = ExportSpellCorrector(spell_corrector)"
      ],
      "metadata": {
        "id": "D5Bo29YdZ7_5"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spell_corrector(\"دیوار کلاس سفد است.\")"
      ],
      "metadata": {
        "id": "B-MykFRas7eE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8fd7b4f8-9cc6-4f7a-e415-0f3833e99124"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'query' (of type EinsumDense) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'key' (of type EinsumDense) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'value' (of type EinsumDense) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'global_self_attention_4' (of type GlobalSelfAttention) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'sequential_8' (of type Sequential) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'feed_forward_8' (of type FeedForward) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'encoder_layer_4' (of type EncoderLayer) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'global_self_attention_5' (of type GlobalSelfAttention) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'sequential_9' (of type Sequential) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'feed_forward_9' (of type FeedForward) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'encoder_layer_5' (of type EncoderLayer) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'global_self_attention_6' (of type GlobalSelfAttention) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'sequential_10' (of type Sequential) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'feed_forward_10' (of type FeedForward) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'encoder_layer_6' (of type EncoderLayer) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'global_self_attention_7' (of type GlobalSelfAttention) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'sequential_11' (of type Sequential) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'feed_forward_11' (of type FeedForward) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'encoder_layer_7' (of type EncoderLayer) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/ops/nn.py:545: UserWarning: You are using a softmax over axis 3 of a tensor of shape (1, 8, 1, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'causal_self_attention_4' (of type CausalSelfAttention) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'cross_attention_4' (of type CrossAttention) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'sequential_12' (of type Sequential) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'feed_forward_12' (of type FeedForward) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'decoder_layer_4' (of type DecoderLayer) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'causal_self_attention_5' (of type CausalSelfAttention) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'cross_attention_5' (of type CrossAttention) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'sequential_13' (of type Sequential) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'feed_forward_13' (of type FeedForward) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'decoder_layer_5' (of type DecoderLayer) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'causal_self_attention_6' (of type CausalSelfAttention) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'cross_attention_6' (of type CrossAttention) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'sequential_14' (of type Sequential) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'feed_forward_14' (of type FeedForward) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'decoder_layer_6' (of type DecoderLayer) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'causal_self_attention_7' (of type CausalSelfAttention) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'cross_attention_7' (of type CrossAttention) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'sequential_15' (of type Sequential) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'feed_forward_15' (of type FeedForward) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'decoder_layer_7' (of type DecoderLayer) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<sos> دیوار کلاس سفید است . <eos> '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.saved_model.save(spell_corrector, export_dir='/content/drive/MyDrive/Spell_correction/saved_model/all')"
      ],
      "metadata": {
        "id": "0NoD37yOs9qq"
      },
      "execution_count": 81,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}