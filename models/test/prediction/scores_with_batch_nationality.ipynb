{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a861dbb-203d-4990-88f2-8430cdf0a605",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24bf717c-155d-4e6c-ab45-b289913a708b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"prediction_with_batch_nationality.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cdf16a53-2abb-44eb-9efd-bd34b12d7fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(sentence, level='char'):\n",
    "    if level == 'char':\n",
    "        return list(sentence)  # Character-level tokenization\n",
    "    elif level == 'word':\n",
    "        return sentence.split()  # Word-level tokenization\n",
    "    else:\n",
    "        raise ValueError(\"Invalid level. Use 'char' or 'word'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a83ada20-d2c7-42fe-bd9b-1408ef45bf5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' چون که هیچ نمی توان بدون بدون دوست صمیمی زندگی . '"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['predicted'][0][5:-6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d86d5bc3-33b2-4b62-9049-a699f6ce9af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['true_tokens'] = df['correct_sentence'].apply(lambda x: tokenize(x, level='word'))\n",
    "df['pred_tokens'] = df['predicted'].apply(lambda x: tokenize(x[5:-6], level='word')) #deleting <sos> and <eos>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93171138-f0e5-47ee-82d2-dafd939c2014",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wrong_sentence</th>\n",
       "      <th>correct_sentence</th>\n",
       "      <th>predicted</th>\n",
       "      <th>true_tokens</th>\n",
       "      <th>pred_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Other] چون که هیچ کس نمی توان بدون دوست صمیمی...</td>\n",
       "      <td>چون که هیچ کس نمی تواند بدون دوست صمیمی زندگی ...</td>\n",
       "      <td>&lt;sos&gt; چون که هیچ نمی توان بدون بدون دوست صمیمی...</td>\n",
       "      <td>[چون, که, هیچ, کس, نمی, تواند, بدون, دوست, صمی...</td>\n",
       "      <td>[چون, که, هیچ, نمی, توان, بدون, بدون, دوست, صم...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[India] به طور مثال اگر یک صنعت کار چیزهای را ...</td>\n",
       "      <td>به طور مثال اگر یک صنعت کار چیزهای را می سازند...</td>\n",
       "      <td>&lt;sos&gt; به طور مثال اگر یک صنعت کار چیزهای را می...</td>\n",
       "      <td>[به, طور, مثال, اگر, یک, صنعت, کار, چیزهای, را...</td>\n",
       "      <td>[به, طور, مثال, اگر, یک, صنعت, کار, چیزهای, را...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Turk] بعضی از این مشکلان ، بودن دور از خانه و...</td>\n",
       "      <td>بعضی از این مشکلان ، بودن دور از خانه واده ، ز...</td>\n",
       "      <td>&lt;sos&gt; بعضی از این مشکلات ، بودن دور از خانواده...</td>\n",
       "      <td>[بعضی, از, این, مشکلان, ،, بودن, دور, از, خانه...</td>\n",
       "      <td>[بعضی, از, این, مشکلات, ،, بودن, دور, از, خانو...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Turk] فاصیلی خانه‌ی آقای مهدوی تا معازه‌ از خ...</td>\n",
       "      <td>فاصیلی خانه‌ی آقای مهدوی تا معازه‌ از خود حدود...</td>\n",
       "      <td>&lt;sos&gt; فاصیلی خانه‌ی آقای مهدوی تا معازه‌ از خو...</td>\n",
       "      <td>[فاصیلی, خانه‌ی, آقای, مهدوی, تا, معازه‌, از, ...</td>\n",
       "      <td>[فاصیلی, خانه‌ی, آقای, مهدوی, تا, معازه‌, از, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Pars] جهان خواران پس از شکست ذلّت بار ب حمایت...</td>\n",
       "      <td>جهان خواران پس از شکست ذلّت بار با حمایت همه ج...</td>\n",
       "      <td>&lt;sos&gt; جهان خواران پس از شکست ذلّت بار ب حمایت ...</td>\n",
       "      <td>[جهان, خواران, پس, از, شکست, ذلّت, بار, با, حم...</td>\n",
       "      <td>[جهان, خواران, پس, از, شکست, ذلّت, بار, ب, حما...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      wrong_sentence  \\\n",
       "0  [Other] چون که هیچ کس نمی توان بدون دوست صمیمی...   \n",
       "1  [India] به طور مثال اگر یک صنعت کار چیزهای را ...   \n",
       "2  [Turk] بعضی از این مشکلان ، بودن دور از خانه و...   \n",
       "3  [Turk] فاصیلی خانه‌ی آقای مهدوی تا معازه‌ از خ...   \n",
       "4  [Pars] جهان خواران پس از شکست ذلّت بار ب حمایت...   \n",
       "\n",
       "                                    correct_sentence  \\\n",
       "0  چون که هیچ کس نمی تواند بدون دوست صمیمی زندگی ...   \n",
       "1  به طور مثال اگر یک صنعت کار چیزهای را می سازند...   \n",
       "2  بعضی از این مشکلان ، بودن دور از خانه واده ، ز...   \n",
       "3  فاصیلی خانه‌ی آقای مهدوی تا معازه‌ از خود حدود...   \n",
       "4  جهان خواران پس از شکست ذلّت بار با حمایت همه ج...   \n",
       "\n",
       "                                           predicted  \\\n",
       "0  <sos> چون که هیچ نمی توان بدون بدون دوست صمیمی...   \n",
       "1  <sos> به طور مثال اگر یک صنعت کار چیزهای را می...   \n",
       "2  <sos> بعضی از این مشکلات ، بودن دور از خانواده...   \n",
       "3  <sos> فاصیلی خانه‌ی آقای مهدوی تا معازه‌ از خو...   \n",
       "4  <sos> جهان خواران پس از شکست ذلّت بار ب حمایت ...   \n",
       "\n",
       "                                         true_tokens  \\\n",
       "0  [چون, که, هیچ, کس, نمی, تواند, بدون, دوست, صمی...   \n",
       "1  [به, طور, مثال, اگر, یک, صنعت, کار, چیزهای, را...   \n",
       "2  [بعضی, از, این, مشکلان, ،, بودن, دور, از, خانه...   \n",
       "3  [فاصیلی, خانه‌ی, آقای, مهدوی, تا, معازه‌, از, ...   \n",
       "4  [جهان, خواران, پس, از, شکست, ذلّت, بار, با, حم...   \n",
       "\n",
       "                                         pred_tokens  \n",
       "0  [چون, که, هیچ, نمی, توان, بدون, بدون, دوست, صم...  \n",
       "1  [به, طور, مثال, اگر, یک, صنعت, کار, چیزهای, را...  \n",
       "2  [بعضی, از, این, مشکلات, ،, بودن, دور, از, خانو...  \n",
       "3  [فاصیلی, خانه‌ی, آقای, مهدوی, تا, معازه‌, از, ...  \n",
       "4  [جهان, خواران, پس, از, شکست, ذلّت, بار, ب, حما...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1e276e8-40dc-41b6-adb2-e57f6ba6c29e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mahboub\\miniforge3\\lib\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "C:\\Users\\mahboub\\miniforge3\\lib\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "C:\\Users\\mahboub\\miniforge3\\lib\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    }
   ],
   "source": [
    "df['bleu_score'] = df.apply(lambda row: sentence_bleu([row['true_tokens']], row['pred_tokens']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b1a121f-50d9-4b39-ab91-3ff0170013ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average BLEU Score: 0.5842089207605698\n"
     ]
    }
   ],
   "source": [
    "average_bleu = df['bleu_score'].mean()\n",
    "print(\"Average BLEU Score:\", average_bleu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c5a10eea-ef47-494d-8f08-b7d7ee580ad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inconsistent lengths found in 543 rows.\n"
     ]
    }
   ],
   "source": [
    "df['true_length'] = df['true_tokens'].apply(len)\n",
    "df['pred_length'] = df['pred_tokens'].apply(len)\n",
    "\n",
    "inconsistent_lengths = df[df['true_length'] != df['pred_length']]\n",
    "print(f\"Inconsistent lengths found in {len(inconsistent_lengths)} rows.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96d4e10b-aafc-4357-91bd-0e10088c4434",
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_sequences(row):\n",
    "    min_len = min(len(row['true_tokens']), len(row['pred_tokens']))\n",
    "    row['true_tokens'] = row['true_tokens'][:min_len]\n",
    "    row['pred_tokens'] = row['pred_tokens'][:min_len]\n",
    "    return row\n",
    "\n",
    "df = df.apply(align_sequences, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d0126519-e731-404f-956b-c746525cc8fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.7352735094704422\n",
      "Recall: 0.704715100375539\n",
      "F1 Score: 0.6937634792157964\n",
      "Accuracy: 0.704715100375539\n"
     ]
    }
   ],
   "source": [
    "all_true_tokens = sum(df['true_tokens'].tolist(), [])\n",
    "all_pred_tokens = sum(df['pred_tokens'].tolist(), [])\n",
    "\n",
    "precision = precision_score(all_true_tokens, all_pred_tokens, average='weighted', zero_division=1)\n",
    "recall = recall_score(all_true_tokens, all_pred_tokens, average='weighted', zero_division=1)\n",
    "f1 = f1_score(all_true_tokens, all_pred_tokens, average='weighted', zero_division=1)\n",
    "accuracy = accuracy_score(all_true_tokens, all_pred_tokens)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ff10af-f66d-46ab-b7ab-67aee4802ca8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
